# -*- coding: utf-8 -*-
"""traffic_violations_catboost.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11sD-6Ng_h7lMOY-uO77E48hH4hkjO32S
"""

!pip install catboost
!pip install category_encoders
from xgboost import XGBClassifier
from catboost import CatBoostClassifier
from category_encoders import *
from sklearn.preprocessing import OrdinalEncoder
from sklearn.metrics import accuracy_score, f1_score,jaccard_score,multilabel_confusion_matrix
import lightgbm as lgbm
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
import pandas as pd
import numpy as np

df=pd.read_csv('https://data.montgomerycountymd.gov/api/views/4mse-ku6q/rows.csv?accessType=DOWNLOAD')

df1=df.loc[:,[ 'Description','Belts','Property Damage','Fatal','Commercial License','HAZMAT','Commercial Vehicle','Alcohol','Work Zone','Year','Race','Gender','Arrest Type','Violation Type']].dropna()

X=df1.iloc[:,:-1]
y=df1.iloc[:,-1]

X.shape

#split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.02, random_state=42)

#catboost
# model_cat = CatBoostClassifier(iterations=10000,task_type="GPU", devices='0:1',)
# model_cat.fit(X_train, y_train, verbose=0,cat_features=[1,2,3,4,5,6,7,8,10,11,12],text_features=[0])
# accuracy_score(y_test, model_cat.predict(X_test))

model_cat = CatBoostClassifier(task_type="GPU", devices='0:1')
parameters = {'depth'         : [6,8,10,12,14,16],
              'learning_rate' : [0.01, 0.05, 0.1,.2,.5],
              'iterations'    : [500,1000,2000,5000]
              }
grid = GridSearchCV(estimator=model_cat, param_grid = parameters)
grid.fit(X_train, y_train,verbose=0,cat_features=[1,2,3,4,5,6,7,8,10,11,12],text_features=[0])    

# Results from Grid Search
print("\n========================================================")
print(" Results from Grid Search " )
print("========================================================")    

print("\n The best estimator across ALL searched params:\n",
      grid.best_estimator_)

print("\n The best score across ALL searched params:\n",
      grid.best_score_)


print("\n The best parameters across ALL searched params:\n",
      grid.best_params_)

print("\n ========================================================")



c=grid.best_estimator_

print("training")
print("macro f1: ",f1_score(y_train,c.predict(X_train), average='macro'))
print("micro f1: ",f1_score(y_train, c.predict(X_train), average='micro'))
print("macro jaccard: ",jaccard_score(y_train,c.predict(X_train), average='macro'))
print("micro jaccard: ",jaccard_score(y_train, c.predict(X_train), average='micro'))

print("test")
print("macro f1: ",f1_score(y_train,c.predict(X_train), average='macro'))
print("micro f1: ",f1_score(y_train, c.predict(X_train), average='micro'))
print("macro jaccard: ",jaccard_score(y_train,c.predict(X_train), average='macro'))
print("micro jaccard: ",jaccard_score(y_train, c.predict(X_train), average='micro'))

print(multilabel_confusion_matrix(y_test, c.predict(X_test)))