# -*- coding: utf-8 -*-
"""traffic_violations_lgbm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uxNWm-OZaXLNIVP7eMtYEorcAQBJDvJZ
"""

!pip install catboost
!pip install category_encoders
from xgboost import XGBClassifier
from catboost import CatBoostClassifier
from category_encoders import *
from sklearn.preprocessing import OrdinalEncoder
from sklearn.metrics import accuracy_score, f1_score,jaccard_score,multilabel_confusion_matrix
import lightgbm as lgbm
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
import pandas as pd
import numpy as np


df=pd.read_csv('https://data.montgomerycountymd.gov/api/views/4mse-ku6q/rows.csv?accessType=DOWNLOAD')
# df.to_csv('data')
# df=pd.read_csv('data')

#solving problem of unseen classes in label encoding
#https://stackoverflow.com/questions/21057621/sklearn-labelencoder-with-never-seen-before-values

class LabelEncoderExt(object):
    def __init__(self):
        """
        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]
        Unknown will be added in fit and transform will take care of new item. It gives unknown class id
        """
        self.label_encoder = LabelEncoder()
        # self.classes_ = self.label_encoder.classes_

    def fit(self, data_list):
        """
        This will fit the encoder for all the unique values and introduce unknown value
        :param data_list: A list of string
        :return: self
        """
        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])
        self.classes_ = self.label_encoder.classes_

        return self

    def transform(self, data_list):
        """
        This will transform the data_list to id list where the new values get assigned to Unknown class
        :param data_list:
        :return:
        """
        new_data_list = list(data_list)
        for unique_item in np.unique(data_list):
            if unique_item not in self.label_encoder.classes_:
                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]

        return self.label_encoder.transform(new_data_list)

df1=df.loc[:,[ 'Description','Belts','Property Damage','Fatal','Commercial License','HAZMAT','Commercial Vehicle','Alcohol','Work Zone','Year','Race','Gender','Arrest Type','Violation Type']].dropna()

X=df1.iloc[:,:-1]
y=df1.iloc[:,-1]

#split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.02, random_state=42)

for col in X.columns:
  le = LabelEncoderExt()
  le.fit(X_train[col])
  X_train[col]=le.transform(X_train[col])
  X_test[col]=le.transform(X_test[col])

#lgbm

model_lgbm = lgbm.LGBMClassifier(boosting_type='goss',objective='multiclass')
parameters = {'depth'         : [6,8,10,12,14,16],
              'learning_rate' : [.01,.05,0.1,.2],
              'iterations'    : [100, 500,1000,2000,3000]
              }
grid = GridSearchCV(estimator=model_lgbm, param_grid = parameters)
grid.fit(X_train, y_train,categorical_feature=['Description','Belts','Property Damage','Fatal','Commercial License','HAZMAT','Commercial Vehicle','Alcohol','Work Zone','Race','Gender','Arrest Type'])    

# Results from Grid Search
print("\n========================================================")
print(" Results from Grid Search " )
print("========================================================")    

print("\n The best estimator across ALL searched params:\n",
      grid.best_estimator_)

print("\n The best score across ALL searched params:\n",
      grid.best_score_)

print("\n The best parameters across ALL searched params:\n",
      grid.best_params_)

print("\n ========================================================")

c=grid.best_estimator_
print("training")
print("macro f1: ",f1_score(y_train,c.predict(X_train), average='macro'))
print("micro f1: ",f1_score(y_train, c.predict(X_train), average='micro'))
print("macro jaccard: ",jaccard_score(y_train,c.predict(X_train), average='macro'))
print("micro jaccard: ",jaccard_score(y_train, c.predict(X_train), average='micro'))

print("test")
print("macro f1: ",f1_score(y_train,c.predict(X_train), average='macro'))
print("micro f1: ",f1_score(y_train, c.predict(X_train), average='micro'))
print("macro jaccard: ",jaccard_score(y_train,c.predict(X_train), average='macro'))
print("micro jaccard: ",jaccard_score(y_train, c.predict(X_train), average='micro'))

print(multilabel_confusion_matrix(y_test, c.predict(X_test)))