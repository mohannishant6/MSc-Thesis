{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "provider gridsearch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysRIfjyHjfzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "2adb0735-be85-4004-a2ac-a93886b404fe"
      },
      "source": [
        "!pip install catboost\n",
        "!pip install category_encoders\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "import category_encoders as ce\n",
        "from sklearn.preprocessing import OrdinalEncoder,LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score,jaccard_score,multilabel_confusion_matrix,log_loss\n",
        "import lightgbm as lgbm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from sklearn.exceptions import DataConversionWarning\n",
        "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/aa/e61819d04ef2bbee778bf4b3a748db1f3ad23512377e43ecfdc3211437a0/catboost-0.23.2-cp36-none-manylinux1_x86_64.whl (64.8MB)\n",
            "\u001b[K     |████████████████████████████████| 64.8MB 81kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.0.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.23.2\n",
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.6/dist-packages (2.2.2)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.0.5)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.18.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.16.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zn1R7MfP2Nx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_json('https://data.cms.gov/resource/psut-35i4.json')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y6hj3ACP3zO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "7c8db741-e32a-4686-b586-6ab6d1b1a9d4"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>npi</th>\n",
              "      <th>nppes_provider_last_org_name</th>\n",
              "      <th>nppes_provider_first_name</th>\n",
              "      <th>nppes_credentials</th>\n",
              "      <th>nppes_provider_gender</th>\n",
              "      <th>nppes_entity_code</th>\n",
              "      <th>nppes_provider_street1</th>\n",
              "      <th>nppes_provider_city</th>\n",
              "      <th>nppes_provider_zip5</th>\n",
              "      <th>nppes_provider_zip4</th>\n",
              "      <th>nppes_provider_state</th>\n",
              "      <th>nppes_provider_country</th>\n",
              "      <th>specialty_description</th>\n",
              "      <th>description_flag</th>\n",
              "      <th>medicare_prvdr_enroll_status</th>\n",
              "      <th>total_claim_count</th>\n",
              "      <th>total_30_day_fill_count</th>\n",
              "      <th>total_drug_cost</th>\n",
              "      <th>total_day_supply</th>\n",
              "      <th>bene_count</th>\n",
              "      <th>total_claim_count_ge65</th>\n",
              "      <th>total_30_day_fill_count_ge65</th>\n",
              "      <th>total_drug_cost_ge65</th>\n",
              "      <th>total_day_supply_ge65</th>\n",
              "      <th>bene_count_ge65</th>\n",
              "      <th>brand_suppress_flag</th>\n",
              "      <th>generic_claim_count</th>\n",
              "      <th>generic_drug_cost</th>\n",
              "      <th>other_suppress_flag</th>\n",
              "      <th>mapd_claim_count</th>\n",
              "      <th>mapd_drug_cost</th>\n",
              "      <th>pdp_claim_count</th>\n",
              "      <th>pdp_drug_cost</th>\n",
              "      <th>lis_claim_count</th>\n",
              "      <th>lis_drug_cost</th>\n",
              "      <th>nonlis_claim_count</th>\n",
              "      <th>nonlis_drug_cost</th>\n",
              "      <th>opioid_claim_count</th>\n",
              "      <th>opioid_drug_cost</th>\n",
              "      <th>opioid_day_supply</th>\n",
              "      <th>...</th>\n",
              "      <th>antibiotic_bene_count</th>\n",
              "      <th>antipsych_ge65_suppress_flag</th>\n",
              "      <th>antipsych_bene_ge65_suppress_flg</th>\n",
              "      <th>average_age_of_beneficiaries</th>\n",
              "      <th>beneficiary_age_less_65_count</th>\n",
              "      <th>beneficiary_age_65_74_count</th>\n",
              "      <th>beneficiary_age_75_84_count</th>\n",
              "      <th>beneficiary_age_greater_84_count</th>\n",
              "      <th>beneficiary_female_count</th>\n",
              "      <th>beneficiary_male_count</th>\n",
              "      <th>beneficiary_race_white_count</th>\n",
              "      <th>beneficiary_race_black_count</th>\n",
              "      <th>beneficiary_race_asian_pi_count</th>\n",
              "      <th>beneficiary_race_hispanic_count</th>\n",
              "      <th>beneficiary_race_nat_ind_count</th>\n",
              "      <th>beneficiary_race_other_count</th>\n",
              "      <th>beneficiary_nondual_count</th>\n",
              "      <th>beneficiary_dual_count</th>\n",
              "      <th>beneficiary_average_risk_score</th>\n",
              "      <th>nppes_provider_street2</th>\n",
              "      <th>brand_claim_count</th>\n",
              "      <th>brand_drug_cost</th>\n",
              "      <th>other_claim_count</th>\n",
              "      <th>other_drug_cost</th>\n",
              "      <th>la_opioid_claim_count</th>\n",
              "      <th>la_opioid_drug_cost</th>\n",
              "      <th>la_opioid_day_supply</th>\n",
              "      <th>la_opioid_bene_count</th>\n",
              "      <th>la_opioid_prescriber_rate</th>\n",
              "      <th>antipsych_claim_count_ge65</th>\n",
              "      <th>antipsych_drug_cost_ge65</th>\n",
              "      <th>anti_psych_bene_count_ge65</th>\n",
              "      <th>nppes_provider_mi</th>\n",
              "      <th>ge65_suppress_flag</th>\n",
              "      <th>bene_count_ge65_suppress_flag</th>\n",
              "      <th>generic_suppress_flag</th>\n",
              "      <th>lis_suppress_flag</th>\n",
              "      <th>nonlis_suppress_flag</th>\n",
              "      <th>mapd_suppress_flag</th>\n",
              "      <th>pdp_suppress_flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1003000126</td>\n",
              "      <td>ENKESHAFI</td>\n",
              "      <td>ARDALAN</td>\n",
              "      <td>M.D.</td>\n",
              "      <td>M</td>\n",
              "      <td>I</td>\n",
              "      <td>900 SETON DR</td>\n",
              "      <td>CUMBERLAND</td>\n",
              "      <td>21502</td>\n",
              "      <td>1854.0</td>\n",
              "      <td>MD</td>\n",
              "      <td>US</td>\n",
              "      <td>Internal Medicine</td>\n",
              "      <td>S</td>\n",
              "      <td>E</td>\n",
              "      <td>677</td>\n",
              "      <td>695.5</td>\n",
              "      <td>32639.57</td>\n",
              "      <td>14788</td>\n",
              "      <td>234.0</td>\n",
              "      <td>516.0</td>\n",
              "      <td>532.533333</td>\n",
              "      <td>23174.78</td>\n",
              "      <td>11428.0</td>\n",
              "      <td>182.0</td>\n",
              "      <td>#</td>\n",
              "      <td>552.0</td>\n",
              "      <td>5941.53</td>\n",
              "      <td>*</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3032.66</td>\n",
              "      <td>527.0</td>\n",
              "      <td>29606.91</td>\n",
              "      <td>305.0</td>\n",
              "      <td>17267.72</td>\n",
              "      <td>372.0</td>\n",
              "      <td>15371.85</td>\n",
              "      <td>25.0</td>\n",
              "      <td>197.47</td>\n",
              "      <td>134.0</td>\n",
              "      <td>...</td>\n",
              "      <td>104.0</td>\n",
              "      <td>*</td>\n",
              "      <td>*</td>\n",
              "      <td>72.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>220.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>2.1685</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1003000142</td>\n",
              "      <td>KHALIL</td>\n",
              "      <td>RASHID</td>\n",
              "      <td>M.D.</td>\n",
              "      <td>M</td>\n",
              "      <td>I</td>\n",
              "      <td>4126 N HOLLAND SYLVANIA RD</td>\n",
              "      <td>TOLEDO</td>\n",
              "      <td>43623</td>\n",
              "      <td>3536.0</td>\n",
              "      <td>OH</td>\n",
              "      <td>US</td>\n",
              "      <td>Anesthesiology</td>\n",
              "      <td>S</td>\n",
              "      <td>E</td>\n",
              "      <td>1946</td>\n",
              "      <td>2054.8</td>\n",
              "      <td>140189.01</td>\n",
              "      <td>58605</td>\n",
              "      <td>276.0</td>\n",
              "      <td>881.0</td>\n",
              "      <td>919.066667</td>\n",
              "      <td>50838.50</td>\n",
              "      <td>26089.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1711.0</td>\n",
              "      <td>34140.73</td>\n",
              "      <td>NaN</td>\n",
              "      <td>930.0</td>\n",
              "      <td>67081.22</td>\n",
              "      <td>1016.0</td>\n",
              "      <td>73107.79</td>\n",
              "      <td>1184.0</td>\n",
              "      <td>94361.07</td>\n",
              "      <td>762.0</td>\n",
              "      <td>45827.94</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>50895.21</td>\n",
              "      <td>29238.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>143.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>1.8029</td>\n",
              "      <td>SUITE 220</td>\n",
              "      <td>235.0</td>\n",
              "      <td>106048.28</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>37637.86</td>\n",
              "      <td>5853.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>19.23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1003000167</td>\n",
              "      <td>ESCOBAR</td>\n",
              "      <td>JULIO</td>\n",
              "      <td>DDS</td>\n",
              "      <td>M</td>\n",
              "      <td>I</td>\n",
              "      <td>5 PINE CONE RD</td>\n",
              "      <td>DAYTON</td>\n",
              "      <td>89403</td>\n",
              "      <td>7482.0</td>\n",
              "      <td>NV</td>\n",
              "      <td>US</td>\n",
              "      <td>Dentist</td>\n",
              "      <td>S</td>\n",
              "      <td>N</td>\n",
              "      <td>55</td>\n",
              "      <td>55.0</td>\n",
              "      <td>302.01</td>\n",
              "      <td>430</td>\n",
              "      <td>33.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>*</td>\n",
              "      <td>16.0</td>\n",
              "      <td>58.19</td>\n",
              "      <td>39.0</td>\n",
              "      <td>243.82</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.0</td>\n",
              "      <td>61.95</td>\n",
              "      <td>35.0</td>\n",
              "      <td>...</td>\n",
              "      <td>22.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>72.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0598</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>E</td>\n",
              "      <td>#</td>\n",
              "      <td>#</td>\n",
              "      <td>#</td>\n",
              "      <td>*</td>\n",
              "      <td>#</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1003000175</td>\n",
              "      <td>REYES-VASQUEZ</td>\n",
              "      <td>BELINDA</td>\n",
              "      <td>D.D.S.</td>\n",
              "      <td>F</td>\n",
              "      <td>I</td>\n",
              "      <td>322 N AZUSA AVE STE 202</td>\n",
              "      <td>LA PUENTE</td>\n",
              "      <td>91744</td>\n",
              "      <td>4648.0</td>\n",
              "      <td>CA</td>\n",
              "      <td>US</td>\n",
              "      <td>Dentist</td>\n",
              "      <td>S</td>\n",
              "      <td>N</td>\n",
              "      <td>18</td>\n",
              "      <td>18.0</td>\n",
              "      <td>113.81</td>\n",
              "      <td>150</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.0</td>\n",
              "      <td>113.81</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#</td>\n",
              "      <td>#</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#</td>\n",
              "      <td>*</td>\n",
              "      <td>*</td>\n",
              "      <td>*</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1003000282</td>\n",
              "      <td>BLAKEMORE</td>\n",
              "      <td>ROSIE</td>\n",
              "      <td>FNP</td>\n",
              "      <td>F</td>\n",
              "      <td>I</td>\n",
              "      <td>TENNESSEE PRISON FOR WOMEN</td>\n",
              "      <td>NASHVILLE</td>\n",
              "      <td>37243</td>\n",
              "      <td>1.0</td>\n",
              "      <td>TN</td>\n",
              "      <td>US</td>\n",
              "      <td>Nurse Practitioner</td>\n",
              "      <td>S</td>\n",
              "      <td>N</td>\n",
              "      <td>90</td>\n",
              "      <td>110.0</td>\n",
              "      <td>7561.21</td>\n",
              "      <td>2681</td>\n",
              "      <td>11.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>3894.08</td>\n",
              "      <td>1931.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>62.0</td>\n",
              "      <td>984.93</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22.0</td>\n",
              "      <td>485.04</td>\n",
              "      <td>68.0</td>\n",
              "      <td>7076.17</td>\n",
              "      <td>73.0</td>\n",
              "      <td>3947.56</td>\n",
              "      <td>17.0</td>\n",
              "      <td>3613.65</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>62.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.5148</td>\n",
              "      <td>3881 STEWARTS LANE</td>\n",
              "      <td>28.0</td>\n",
              "      <td>6576.28</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>K</td>\n",
              "      <td>NaN</td>\n",
              "      <td>*</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 84 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          npi nppes_provider_last_org_name  ... mapd_suppress_flag pdp_suppress_flag\n",
              "0  1003000126                    ENKESHAFI  ...                NaN               NaN\n",
              "1  1003000142                       KHALIL  ...                NaN               NaN\n",
              "2  1003000167                      ESCOBAR  ...                NaN               NaN\n",
              "3  1003000175                REYES-VASQUEZ  ...                  *                 *\n",
              "4  1003000282                    BLAKEMORE  ...                NaN               NaN\n",
              "\n",
              "[5 rows x 84 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDrb2b1Fcij8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "addf6d70-5786-4976-940f-1bda6fcaabea"
      },
      "source": [
        "df.specialty_description.unique()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Internal Medicine', 'Anesthesiology', 'Dentist',\n",
              "       'Nurse Practitioner', 'Family Practice', 'Obstetrics & Gynecology',\n",
              "       'General Surgery', 'Urology', 'Cardiac Surgery', 'Pharmacist',\n",
              "       'Physician Assistant', 'Dermatology', 'Optometry',\n",
              "       'Physical Medicine and Rehabilitation', 'Radiation Oncology',\n",
              "       'Infectious Disease', 'Orthopedic Surgery', 'Endocrinology',\n",
              "       'Psychiatry', 'Rheumatology', 'General Practice',\n",
              "       'Emergency Medicine', 'Neurology', 'Nephrology',\n",
              "       'Preventive Medicine', 'Licensed Clinical Social Worker',\n",
              "       'Orthopaedic Surgery', 'Ophthalmology', 'Pulmonary Disease',\n",
              "       'Otolaryngology', 'Plastic and Reconstructive Surgery',\n",
              "       'Cardiology', 'Psychiatry & Neurology',\n",
              "       'Interventional Cardiology', 'Gastroenterology',\n",
              "       'Diagnostic Radiology', 'Geriatric Medicine', 'Neurosurgery',\n",
              "       'Interventional Radiology', 'Neuropsychiatry', 'Pain Management',\n",
              "       'Oral Surgery (Dentist only)', 'Podiatry', 'Pediatric Medicine',\n",
              "       'Hematology-Oncology',\n",
              "       'Student in an Organized Health Care Education/Training Program',\n",
              "       'Certified Nurse Midwife', 'Exclusive Provider Organization',\n",
              "       'Specialist', 'Medical Oncology', 'Thoracic Surgery',\n",
              "       'Allergy/ Immunology', 'Sports Medicine', 'Nuclear Medicine',\n",
              "       'Certified Clinical Nurse Specialist', 'Hand Surgery',\n",
              "       'Hospitalist', 'Hospice and Palliative Care', 'Naturopath',\n",
              "       'Marriage & Family Therapist', 'Surgery',\n",
              "       'Advanced Heart Failure and Transplant Cardiology',\n",
              "       'Osteopathic Manipulative Medicine', 'Vascular Surgery',\n",
              "       'Behavior Analyst', 'Critical Care (Intensivists)'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8UHcuYaQRUG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e7390d8d-b173-4087-dd02-7b94a923fe98"
      },
      "source": [
        "df['nppes_credentials']=df.nppes_credentials.str.replace(\".\",\"\")\n",
        "df['nppes_credentials']=df.nppes_credentials.str.replace(\",\",\"\")\n",
        "df['nppes_credentials']=df.nppes_credentials.str.replace(\"-\",\"\")\n",
        "df['nppes_credentials']=df.nppes_credentials.str.replace(\"/\",\"\")\n",
        "df['nppes_credentials']=df.nppes_credentials.str.replace(\" \",\"\")\n",
        "df.nppes_credentials.nunique()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5mhAtvU4wxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "df=df[[  'nppes_credentials', 'nppes_provider_gender',\n",
        "       'nppes_provider_city', 'nppes_provider_zip5',\n",
        "       'nppes_provider_state', 'nppes_provider_country',\n",
        "       'specialty_description', 'medicare_prvdr_enroll_status','bene_count']]\n",
        "\n",
        "df['nppes_provider_zip5']=df['nppes_provider_zip5'].astype(str)\n",
        "df.dropna(inplace=True)\n",
        "df['n_patients']=pd.qcut(df.bene_count,4)\n",
        "\n",
        "X=df.iloc[:,:-2]\n",
        "y=df.iloc[:,-1]\n",
        "y=pd.Series(LabelEncoder().fit_transform(y))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-ZP6WThOHwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "86029230-1da1-4c8b-a016-3ab6103ec7b8"
      },
      "source": [
        "pd.Series(y).value_counts()/pd.Series(y).value_counts().sum()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.255196\n",
              "3    0.250577\n",
              "2    0.248268\n",
              "1    0.245958\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozYmWD9pjfz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#label encoder to encode unseen values too\n",
        "class LabelEncoderExt(object):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
        "        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
        "        \"\"\"\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        # self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "    def fit(self, data_list):\n",
        "        \"\"\"\n",
        "        This will fit the encoder for all the unique values and introduce unknown value\n",
        "        :param data_list: A list of string\n",
        "        :return: self\n",
        "        \"\"\"\n",
        "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
        "        self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, data_list):\n",
        "        \"\"\"\n",
        "        This will transform the data_list to id list where the new values get assigned to Unknown class\n",
        "        :param data_list:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        new_data_list = list(data_list)\n",
        "        for unique_item in np.unique(data_list):\n",
        "            if unique_item not in self.label_encoder.classes_:\n",
        "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
        "\n",
        "        return self.label_encoder.transform(new_data_list)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PbWO133jfz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#encodings and split\n",
        "\n",
        "def onehot_all(X,y,ratio):\n",
        "    \n",
        "    #split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=42)\n",
        "    \n",
        "    obj_cols=X.select_dtypes('object').columns\n",
        "    enc=ce.OneHotEncoder(cols=obj_cols,handle_missing='return_nan').fit(X_train,y_train)\n",
        "    X_train=enc.transform(X_train)\n",
        "    X_test=enc.transform(X_test)\n",
        "    \n",
        "    return X_train, X_test,y_train, y_test\n",
        "\n",
        "def target_all(X,y,ratio):\n",
        "    \n",
        "    #split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=42)\n",
        "    \n",
        "#     obj_cols=X.select_dtypes('object').columns\n",
        "    enc=ce.TargetEncoder(handle_missing='return_nan').fit(X_train,y_train)\n",
        "    X_train=enc.transform(X_train)\n",
        "    X_test=enc.transform(X_test)\n",
        "    \n",
        "    return X_train,X_test,y_train, y_test\n",
        "    \n",
        "def onehot_target(X,y,ratio,thresh):\n",
        "    \n",
        "    #split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=42)\n",
        "    \n",
        "    low_card_cols,high_card_cols=[],[]\n",
        "    obj_cols=X.select_dtypes('object').columns\n",
        "    for col in obj_cols:\n",
        "        if X_train[col].nunique()<=thresh:\n",
        "            low_card_cols.append(col)\n",
        "        else:\n",
        "            high_card_cols.append(col)\n",
        "    \n",
        "    print(low_card_cols,high_card_cols)\n",
        "    \n",
        "    enc=ce.OneHotEncoder(cols=low_card_cols,handle_missing='return_nan').fit(X_train,y_train)\n",
        "    X_train=enc.transform(X_train)\n",
        "    X_test=enc.transform(X_test)\n",
        "    \n",
        "    enc=ce.TargetEncoder(cols=high_card_cols,handle_missing='return_nan').fit(X_train,y_train)\n",
        "    X_train=enc.transform(X_train)\n",
        "    X_test=enc.transform(X_test)\n",
        "    \n",
        "    return X_train,X_test,y_train, y_test\n",
        "\n",
        "def target_encode_multiclass(X,y,ratio):\n",
        "    class_names=y.unique()\n",
        "    y_classes=pd.DataFrame(columns=class_names)\n",
        "\n",
        "    for class_ in class_names:\n",
        "      y_class_=y.map(lambda x: 1 if x==class_ else 0)\n",
        "      y_classes[class_]=y_class_\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y_classes, test_size=ratio, random_state=42)\n",
        "\n",
        "    X_train_obj=X_train.select_dtypes('object')\n",
        "    X_test_obj=X_test.select_dtypes('object')\n",
        "    X_train=X_train.select_dtypes(exclude='object')\n",
        "    X_test=X_test.select_dtypes(exclude='object')\n",
        "\n",
        "    for class_ in class_names:\n",
        "      \n",
        "      enc=ce.TargetEncoder(handle_missing='return_nan').fit(X_train_obj,y_train[class_])\n",
        "      temp=enc.transform(X_train_obj)\n",
        "      temp.columns=[str(x)+'_'+str(class_) for x in temp.columns]\n",
        "      X_train=pd.concat([X_train,temp],axis=1)\n",
        "      temp=enc.transform(X_test_obj)\n",
        "      temp.columns=[str(x)+'_'+str(class_) for x in temp.columns]\n",
        "      X_test=pd.concat([X_test,temp],axis=1)\n",
        "      \n",
        "    y_train=y_train.apply(lambda row: 1 if row[1]==1 else 2 if row[2]==1 else 3 if row[3]==1 else 0, axis=1)\n",
        "    y_test=y_test.apply(lambda row: 1 if row[1]==1 else 2 if row[2]==1 else 3 if row[3]==1 else 0, axis=1)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "            \n",
        "def onehot_target_encode_multiclass(X,y,ratio,thresh):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=42)\n",
        "\n",
        "    low_card_cols,high_card_cols=[],[]\n",
        "    obj_cols=X.select_dtypes('object').columns\n",
        "    for col in obj_cols:\n",
        "        if X_train[col].nunique()<=thresh:\n",
        "            low_card_cols.append(col)\n",
        "        else:\n",
        "            high_card_cols.append(col)\n",
        "    \n",
        "    enc=ce.OneHotEncoder(cols=low_card_cols,handle_missing='return_nan').fit(X_train,y_train)\n",
        "    X_train=enc.transform(X_train)\n",
        "    X_test=enc.transform(X_test)\n",
        "\n",
        "\n",
        "    enc=ce.OneHotEncoder(handle_missing='return_nan').fit(y_train)\n",
        "    y_train_wide=enc.transform(y_train)\n",
        "    y_test_wide=enc.transform(y_test)\n",
        "\n",
        "\n",
        "    class_names=y_train_wide.columns\n",
        "    # y_classes=pd.DataFrame(columns=class_names)\n",
        "\n",
        "    # for class_ in class_names:\n",
        "    #   y_class_=y.map(lambda x: 1 if x==class_ else 0)\n",
        "    #   y_classes[class_]=y_class_\n",
        "\n",
        "    \n",
        "    X_train_obj=X_train.select_dtypes('object')\n",
        "    X_test_obj=X_test.select_dtypes('object')\n",
        "    X_train=X_train.select_dtypes(exclude='object')\n",
        "    X_test=X_test.select_dtypes(exclude='object')\n",
        "\n",
        "    for class_ in class_names:\n",
        "      \n",
        "      enc=ce.TargetEncoder(handle_missing='return_nan').fit(X_train_obj,y_train_wide[class_])\n",
        "      temp=enc.transform(X_train_obj)\n",
        "      temp.columns=[str(x)+'_'+str(class_) for x in temp.columns]\n",
        "      X_train=pd.concat([X_train,temp],axis=1)\n",
        "      temp=enc.transform(X_test_obj)\n",
        "      temp.columns=[str(x)+'_'+str(class_) for x in temp.columns]\n",
        "      X_test=pd.concat([X_test,temp],axis=1)\n",
        "      \n",
        "    # y_train=y_train.apply(lambda row: 1 if row[1]==1 else 2 if row[2]==1 else 3 if row[3]==1 else 0, axis=1)\n",
        "    # y_test=y_test.apply(lambda row: 1 if row[1]==1 else 2 if row[2]==1 else 3 if row[3]==1 else 0, axis=1)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmAQA0NNjfz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train_evaluate( X_train,X_test,y_train, y_test,cat_features=None):\n",
        "\n",
        "  # try:\n",
        "  # print(\"lightgbm training with gridsearch\")\n",
        "\n",
        "  # model = lgbm.LGBMClassifier(boosting_type='goss')\n",
        "  # grid = GridSearchCV(estimator=model, param_grid = parameters)\n",
        "  # grid.fit(X_train, y_train,verbose=0)    \n",
        "\n",
        "  # model=grid.best_estimator_\n",
        "  # evaluate(model,X_test,y_test)\n",
        "  # # except: pass\n",
        "\n",
        "  # try:\n",
        "  #   print(\"catboost training with gridsearch\")\n",
        "\n",
        "  #   model = CatBoostClassifier(\n",
        "  #       task_type=\"GPU\", devices='0:1'\n",
        "  #   )\n",
        "  #   grid = GridSearchCV(estimator=model, param_grid = parameters)\n",
        "  #   grid.fit(X_train, y_train,verbose=0)    \n",
        "\n",
        "  #   model=grid.best_estimator_\n",
        "  #   evaluate(model,X_test,y_test)\n",
        "  # except:pass\n",
        "\n",
        "  try:\n",
        "    print(\"xgboost training with gridsearch\")\n",
        "\n",
        "    model = XGBClassifier(tree_method='gpu_hist', gpu_id=0)\n",
        "    grid = GridSearchCV(estimator=model, param_grid = parameters_xgb)\n",
        "    grid.fit(X_train, y_train,verbose=0)    \n",
        "\n",
        "    model=grid.best_estimator_\n",
        "    evaluate(model,X_test,y_test)\n",
        "  except:pass\n",
        "\n",
        "  try:  \n",
        "    print(\"RF training with gridsearch\")\n",
        "    \n",
        "    model=RandomForestClassifier()\n",
        "    grid = GridSearchCV(estimator=model, param_grid = parameters_RF)\n",
        "    grid.fit(X_train.fillna(value=0), y_train)    \n",
        "\n",
        "    model=grid.best_estimator_\n",
        "    evaluate(model,X_test.fillna(value=0),y_test)\n",
        "  except:pass\n",
        "    \n",
        "def train_evaluate_with_cat_feat( X_train,X_test,y_train, y_test,cat_features=None):\n",
        "  try:\n",
        "    print(\"lightgbm training with gridsearch\")\n",
        "    for col in cat_features:\n",
        "        le = LabelEncoderExt()\n",
        "        le.fit(X_train[col])\n",
        "        X_train[col]=le.transform(X_train[col])\n",
        "        X_test[col]=le.transform(X_test[col])\n",
        "\n",
        "    fit_params={'categorical_feature':cat_features}\n",
        "    model = lgbm.LGBMClassifier(boosting_type='goss')\n",
        "    grid = GridSearchCV(estimator=model, param_grid = parameters)\n",
        "    grid.fit(X_train, y_train,verbose=0,**fit_params)    \n",
        "\n",
        "    model=grid.best_estimator_\n",
        "    evaluate(model,X_test,y_test)\n",
        "  except:pass\n",
        "\n",
        "  try:\n",
        "    print(\"catboost training with gridsearch\")\n",
        "    fit_params={'cat_features':cat_features}\n",
        "    model = CatBoostClassifier(\n",
        "        task_type=\"GPU\", devices='0:1'\n",
        "    )\n",
        "    grid = GridSearchCV(estimator=model, param_grid = parameters)\n",
        "    grid.fit(X_train, y_train,verbose=0,**fit_params)    \n",
        "\n",
        "    model=grid.best_estimator_\n",
        "    evaluate(model,X_test,y_test)\n",
        "  except:pass"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8lipuKDjf0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#evaluation function\n",
        "\n",
        "def evaluate(model,X_test,y_test):\n",
        "    \n",
        "    pred=model.predict(X_test)\n",
        "    pred_proba=model.predict_proba(X_test)\n",
        "\n",
        "    print('accuracy:',accuracy_score(y_test,pred))\n",
        "    print('f1 macro:',f1_score(y_test,pred, average='macro'))\n",
        "    # print('f1_micro:',f1_score(y_test,pred, average='micro'))\n",
        "#     print(pd.Series(pred).unique())\n",
        "    print('log_loss:',log_loss(y_test,pred_proba,labels=[1,2,3,0]))\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDpzbqqsjf0M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6c24bcef-aad0-492b-fede-be5c7cc06b02"
      },
      "source": [
        "# X=df.iloc[:,:-1]\n",
        "# y=df.iloc[:,-1:]\n",
        "# X_train,X_test,y_train, y_test=onehot_all(df.iloc[:,:-1],y,.2)\n",
        "# X_train,X_test,y_train, y_test=target_all(df.iloc[:,:-1],y,ratio=.2)\n",
        "# X_train,X_test,y_train, y_test=onehot_target(df.iloc[:,:-1],y,ratio=.2,thresh=10)\n",
        "\n",
        "\n",
        "parameters = {'depth'         : [6,8,10],\n",
        "              'learning_rate' : [.01,.05,.1,.2],\n",
        "              'n_estimators': [500,1000],\n",
        "              # 'reg_lambda': [0,0.5,1.0]\n",
        "              # 'iterations'    : [500,1000,2000]\n",
        "              }\n",
        "# parameters = {'depth'         : [4],\n",
        "#               'learning_rate' : [.2],\n",
        "#               # 'iterations'    : [50]\n",
        "#               }\n",
        "parameters_xgb = {\n",
        "'n_estimators': [500,1000],\n",
        "    # 'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'max_depth' : [6,8,10],\n",
        "    'criterion' :['gini', 'entropy'],\n",
        "    # 'reg_lambda': [0,0.5,1.0]\n",
        "        }\n",
        "\n",
        "# parameters_xgb = {\n",
        "# 'n_estimators': [50],\n",
        "# #     'max_features': ['auto', 'sqrt', 'log2'],\n",
        "#     'max_depth' : [4],\n",
        "# #     'criterion' :['gini', 'entropy']\n",
        "#         }\n",
        "parameters_RF={'max_depth':[6,8,10], 'n_estimators':[500,1000]}\n",
        "# parameters_RF={'max_depth':[2], 'n_estimators':[10]}\n",
        "\n",
        "\n",
        "print(\"##############################\")\n",
        "print(\"now with target for all\")\n",
        "X_train,X_test,y_train, y_test=target_all(X,y,.2)\n",
        "train_evaluate( X_train,X_test,y_train, y_test)\n",
        "print(\"##############################\")\n",
        "print(\"now with mixed for all\")\n",
        "X_train,X_test,y_train, y_test=onehot_target(X,y,.2,8)\n",
        "train_evaluate( X_train,X_test,y_train, y_test)\n",
        "print(\"##############################\")\n",
        "print(\"now with one hot for all\")\n",
        "X_train,X_test,y_train, y_test=onehot_all(X,y,.2)\n",
        "train_evaluate( X_train,X_test,y_train, y_test)\n",
        "print(\"##############################\")\n",
        "print(\"now with native cat features support\")\n",
        "X_train,X_test,y_train, y_test=train_test_split(X, y, test_size=.2, random_state=42)\n",
        "train_evaluate_with_cat_feat(X_train,X_test,y_train, y_test,cat_features=list(X_train.select_dtypes('object').columns))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##############################\n",
            "now with target for all\n",
            "xgboost training with gridsearch\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "xgboost.core.XGBoostError: [16:36:45] /workspace/src/tree/updater_gpu_hist.cu:1407: Exception in gpu_hist: NCCL failure :unhandled cuda error /workspace/src/tree/../common/device_helpers.cuh(896)\n",
            "\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7ff398e06cb4]\n",
            "  [bt] (1) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(xgboost::tree::GPUHistMakerSpecialised<xgboost::detail::GradientPairInternal<double> >::Update(xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*, xgboost::DMatrix*, std::vector<xgboost::RegTree*, std::allocator<xgboost::RegTree*> > const&)+0x1270) [0x7ff3990427f0]\n",
            "  [bt] (2) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(xgboost::gbm::GBTree::BoostNewTrees(xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*, xgboost::DMatrix*, int, std::vector<std::unique_ptr<xgboost::RegTree, std::default_delete<xgboost::RegTree> >, std::allocator<std::unique_ptr<xgboost::RegTree, std::default_delete<xgboost::RegTree> > > >*)+0xa81) [0x7ff398e8c791]\n",
            "  [bt] (3) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(xgboost::gbm::GBTree::DoBoost(xgboost::DMatrix*, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*, xgboost::ObjFunction*)+0x3f1) [0x7ff398e8d321]\n",
            "  [bt] (4) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::UpdateOneIter(int, xgboost::DMatrix*)+0x396) [0x7ff398ea0556]\n",
            "  [bt] (5) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x35) [0x7ff398e03aa5]\n",
            "  [bt] (6) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7ff3cc62adae]\n",
            "  [bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x22f) [0x7ff3cc62a71f]\n",
            "  [bt] (8) /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2b4) [0x7ff3cc83e5c4]\n",
            "\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "xgboost.core.XGBoostError: [16:36:46] /workspace/src/tree/updater_gpu_hist.cu:1407: Exception in gpu_hist: NCCL failure :unhandled cuda error /workspace/src/tree/../common/device_helpers.cuh(896)\n",
            "\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7ff398e06cb4]\n",
            "  [bt] (1) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(xgboost::tree::GPUHistMakerSpecialised<xgboost::detail::GradientPairInternal<double> >::Update(xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*, xgboost::DMatrix*, std::vector<xgboost::RegTree*, std::allocator<xgboost::RegTree*> > const&)+0x1270) [0x7ff3990427f0]\n",
            "  [bt] (2) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(xgboost::gbm::GBTree::BoostNewTrees(xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*, xgboost::DMatrix*, int, std::vector<std::unique_ptr<xgboost::RegTree, std::default_delete<xgboost::RegTree> >, std::allocator<std::unique_ptr<xgboost::RegTree, std::default_delete<xgboost::RegTree> > > >*)+0xa81) [0x7ff398e8c791]\n",
            "  [bt] (3) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(xgboost::gbm::GBTree::DoBoost(xgboost::DMatrix*, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*, xgboost::ObjFunction*)+0x3f1) [0x7ff398e8d321]\n",
            "  [bt] (4) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::UpdateOneIter(int, xgboost::DMatrix*)+0x396) [0x7ff398ea0556]\n",
            "  [bt] (5) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x35) [0x7ff398e03aa5]\n",
            "  [bt] (6) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7ff3cc62adae]\n",
            "  [bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x22f) [0x7ff3cc62a71f]\n",
            "  [bt] (8) /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2b4) [0x7ff3cc83e5c4]\n",
            "\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RF training with gridsearch\n",
            "##############################\n",
            "now with mixed for all\n",
            "['nppes_provider_gender', 'nppes_provider_country', 'medicare_prvdr_enroll_status'] ['nppes_credentials', 'nppes_provider_city', 'nppes_provider_zip5', 'nppes_provider_state', 'specialty_description']\n",
            "xgboost training with gridsearch\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "xgboost.core.XGBoostError: [16:37:19] /workspace/src/tree/updater_gpu_hist.cu:1407: Exception in gpu_hist: NCCL failure :unhandled cuda error /workspace/src/tree/../common/device_helpers.cuh(896)\n",
            "\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7ff398e06cb4]\n",
            "  [bt] (1) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(xgboost::tree::GPUHistMakerSpecialised<xgboost::detail::GradientPairInternal<double> >::Update(xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*, xgboost::DMatrix*, std::vector<xgboost::RegTree*, std::allocator<xgboost::RegTree*> > const&)+0x1270) [0x7ff3990427f0]\n",
            "  [bt] (2) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(xgboost::gbm::GBTree::BoostNewTrees(xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*, xgboost::DMatrix*, int, std::vector<std::unique_ptr<xgboost::RegTree, std::default_delete<xgboost::RegTree> >, std::allocator<std::unique_ptr<xgboost::RegTree, std::default_delete<xgboost::RegTree> > > >*)+0xa81) [0x7ff398e8c791]\n",
            "  [bt] (3) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(xgboost::gbm::GBTree::DoBoost(xgboost::DMatrix*, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*, xgboost::ObjFunction*)+0x3f1) [0x7ff398e8d321]\n",
            "  [bt] (4) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::UpdateOneIter(int, xgboost::DMatrix*)+0x396) [0x7ff398ea0556]\n",
            "  [bt] (5) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x35) [0x7ff398e03aa5]\n",
            "  [bt] (6) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7ff3cc62adae]\n",
            "  [bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x22f) [0x7ff3cc62a71f]\n",
            "  [bt] (8) /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2b4) [0x7ff3cc83e5c4]\n",
            "\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "xgboost.core.XGBoostError: [16:37:20] /workspace/src/tree/updater_gpu_hist.cu:1407: Exception in gpu_hist: NCCL failure :unhandled cuda error /workspace/src/tree/../common/device_helpers.cuh(896)\n",
            "\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7ff398e06cb4]\n",
            "  [bt] (1) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(xgboost::tree::GPUHistMakerSpecialised<xgboost::detail::GradientPairInternal<double> >::Update(xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*, xgboost::DMatrix*, std::vector<xgboost::RegTree*, std::allocator<xgboost::RegTree*> > const&)+0x1270) [0x7ff3990427f0]\n",
            "  [bt] (2) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(xgboost::gbm::GBTree::BoostNewTrees(xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*, xgboost::DMatrix*, int, std::vector<std::unique_ptr<xgboost::RegTree, std::default_delete<xgboost::RegTree> >, std::allocator<std::unique_ptr<xgboost::RegTree, std::default_delete<xgboost::RegTree> > > >*)+0xa81) [0x7ff398e8c791]\n",
            "  [bt] (3) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(xgboost::gbm::GBTree::DoBoost(xgboost::DMatrix*, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*, xgboost::ObjFunction*)+0x3f1) [0x7ff398e8d321]\n",
            "  [bt] (4) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::UpdateOneIter(int, xgboost::DMatrix*)+0x396) [0x7ff398ea0556]\n",
            "  [bt] (5) /usr/local/lib/python3.6/dist-packages/xgboost/./lib/libxgboost.so(XGBoosterUpdateOneIter+0x35) [0x7ff398e03aa5]\n",
            "  [bt] (6) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7ff3cc62adae]\n",
            "  [bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x22f) [0x7ff3cc62a71f]\n",
            "  [bt] (8) /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2b4) [0x7ff3cc83e5c4]\n",
            "\n",
            "\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RF training with gridsearch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riRcCcOAJWIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "proba"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}