{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mohannishant6/thesis/blob/master/notebooks/poker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "ysRIfjyHjfzq",
    "outputId": "e3b01f49-550e-42fb-8a18-bbea50bcd6c7"
   },
   "outputs": [],
   "source": [
    "# !pip install catboost\n",
    "# !pip install category_encoders\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import OrdinalEncoder,LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score,jaccard_score,multilabel_confusion_matrix,log_loss\n",
    "import lightgbm as lgbm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "bINdQWsOjfzv",
    "outputId": "d62ada2f-1ed2-416f-c14c-b2f11b211c59"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   10\n",
       "0   1  10   1  11   1  13   1  12   1   1   9\n",
       "1   2  11   2  13   2  10   2  12   2   1   9\n",
       "2   3  12   3  11   3  13   3  10   3   1   9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand-training-true.data',header=None)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y73BTwRVjfz0"
   },
   "outputs": [],
   "source": [
    "df[0]=df[0].astype(str)\n",
    "df[2]=df[2].astype(str)\n",
    "df[4]=df[4].astype(str)\n",
    "df[6]=df[6].astype(str)\n",
    "df[8]=df[8].astype(str)\n",
    "# df[10]=df[10].astype(str)\n",
    "\n",
    "X=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ozYmWD9pjfz4"
   },
   "outputs": [],
   "source": [
    "#label encoder to encode unseen values too\n",
    "class LabelEncoderExt(object):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
    "        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
    "        \"\"\"\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        # self.classes_ = self.label_encoder.classes_\n",
    "\n",
    "    def fit(self, data_list):\n",
    "        \"\"\"\n",
    "        This will fit the encoder for all the unique values and introduce unknown value\n",
    "        :param data_list: A list of string\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
    "        self.classes_ = self.label_encoder.classes_\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_list):\n",
    "        \"\"\"\n",
    "        This will transform the data_list to id list where the new values get assigned to Unknown class\n",
    "        :param data_list:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        new_data_list = list(data_list)\n",
    "        for unique_item in np.unique(data_list):\n",
    "            if unique_item not in self.label_encoder.classes_:\n",
    "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
    "\n",
    "        return self.label_encoder.transform(new_data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6PbWO133jfz8"
   },
   "outputs": [],
   "source": [
    "#encodings and split\n",
    "\n",
    "def onehot_all(X,y,ratio):\n",
    "    \n",
    "    #split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=42)\n",
    "    \n",
    "    obj_cols=X.select_dtypes('object').columns\n",
    "    enc=ce.OneHotEncoder(cols=obj_cols,handle_missing='return_nan').fit(X_train,y_train)\n",
    "    X_train=enc.transform(X_train)\n",
    "    X_test=enc.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test,y_train, y_test\n",
    "\n",
    "def target_all(X,y,ratio):\n",
    "    \n",
    "    #split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=42)\n",
    "    \n",
    "#     obj_cols=X.select_dtypes('object').columns\n",
    "    enc=ce.TargetEncoder(handle_missing='return_nan').fit(X_train,y_train)\n",
    "    X_train=enc.transform(X_train)\n",
    "    X_test=enc.transform(X_test)\n",
    "    \n",
    "    return X_train,X_test,y_train, y_test\n",
    "    \n",
    "def onehot_target(X,y,ratio,thresh):\n",
    "    \n",
    "    #split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=42)\n",
    "    \n",
    "    low_card_cols,high_card_cols=[],[]\n",
    "    obj_cols=X.select_dtypes('object').columns\n",
    "    for col in obj_cols:\n",
    "        if X_train[col].nunique()<=thresh:\n",
    "            low_card_cols.append(col)\n",
    "        else:\n",
    "            high_card_cols.append(col)\n",
    "    \n",
    "    print(low_card_cols,high_card_cols)\n",
    "    \n",
    "    enc=ce.OneHotEncoder(cols=low_card_cols,handle_missing='return_nan').fit(X_train,y_train)\n",
    "    X_train=enc.transform(X_train)\n",
    "    X_test=enc.transform(X_test)\n",
    "    \n",
    "    enc=ce.TargetEncoder(cols=high_card_cols,handle_missing='return_nan').fit(X_train,y_train)\n",
    "    X_train=enc.transform(X_train)\n",
    "    X_test=enc.transform(X_test)\n",
    "    \n",
    "    return X_train,X_test,y_train, y_test\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EmAQA0NNjfz_"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_evaluate( X_train,X_test,y_train, y_test,cat_features=None):\n",
    "\n",
    "  try:\n",
    "    print(\"lightgbm training with gridsearch\")\n",
    "\n",
    "    model = lgbm.LGBMClassifier(boosting_type='goss')\n",
    "    grid = GridSearchCV(estimator=model, param_grid = parameters)\n",
    "    grid.fit(X_train, y_train,verbose=0)    \n",
    "\n",
    "    model=grid.best_estimator_\n",
    "    evaluate(model,X_test,y_test)\n",
    "  except: pass\n",
    "\n",
    "  try:\n",
    "    print(\"catboost training with gridsearch\")\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        task_type=\"GPU\", devices='0:1'\n",
    "    )\n",
    "    grid = GridSearchCV(estimator=model, param_grid = parameters)\n",
    "    grid.fit(X_train, y_train,verbose=0)    \n",
    "\n",
    "    model=grid.best_estimator_\n",
    "    evaluate(model,X_test,y_test)\n",
    "  except:pass\n",
    "\n",
    "  try:\n",
    "    print(\"xgboost training with gridsearch\")\n",
    "\n",
    "    model = XGBClassifier(tree_method='gpu_hist', gpu_id=0)\n",
    "    grid = GridSearchCV(estimator=model, param_grid = parameters_xgb)\n",
    "    grid.fit(X_train, y_train,verbose=0)    \n",
    "\n",
    "    model=grid.best_estimator_\n",
    "    evaluate(model,X_test,y_test)\n",
    "  except:pass\n",
    "\n",
    "  try:  \n",
    "    print(\"RF training with gridsearch\")\n",
    "    \n",
    "    model=RandomForestClassifier()\n",
    "    grid = GridSearchCV(estimator=model, param_grid = parameters_RF)\n",
    "    grid.fit(X_train, y_train)    \n",
    "\n",
    "    model=grid.best_estimator_\n",
    "    evaluate(model,X_test,y_test)\n",
    "  except:pass\n",
    "    \n",
    "def train_evaluate_with_cat_feat( X_train,X_test,y_train, y_test,cat_features=None):\n",
    "  try:\n",
    "    print(\"lightgbm training with gridsearch\")\n",
    "    for col in cat_features:\n",
    "        le = LabelEncoderExt()\n",
    "        le.fit(X_train[col])\n",
    "        X_train[col]=le.transform(X_train[col])\n",
    "        X_test[col]=le.transform(X_test[col])\n",
    "\n",
    "    fit_params={'categorical_feature':cat_features}\n",
    "    model = lgbm.LGBMClassifier(boosting_type='goss')\n",
    "    grid = GridSearchCV(estimator=model, param_grid = parameters)\n",
    "    grid.fit(X_train, y_train,verbose=0,**fit_params)    \n",
    "\n",
    "    model=grid.best_estimator_\n",
    "    evaluate(model,X_test,y_test)\n",
    "  except:pass\n",
    "\n",
    "  try:\n",
    "    print(\"catboost training with gridsearch\")\n",
    "    fit_params={'cat_features':cat_features}\n",
    "    model = CatBoostClassifier(\n",
    "        task_type=\"GPU\", devices='0:1'\n",
    "    )\n",
    "    grid = GridSearchCV(estimator=model, param_grid = parameters)\n",
    "    grid.fit(X_train, y_train,verbose=0,**fit_params)    \n",
    "\n",
    "    model=grid.best_estimator_\n",
    "    evaluate(model,X_test,y_test)\n",
    "  except:pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T8lipuKDjf0D"
   },
   "outputs": [],
   "source": [
    "#evaluation function\n",
    "\n",
    "def evaluate(model,X_test,y_test):\n",
    "    \n",
    "    pred=model.predict(X_test)\n",
    "    pred_proba=model.predict_proba(X_test)\n",
    "\n",
    "    print('accuracy:',accuracy_score(y_test,pred))\n",
    "    print('f1 macro:',f1_score(y_test,pred, average='macro'))\n",
    "    print('f1_micro:',f1_score(y_test,pred, average='micro'))\n",
    "#     print(pd.Series(pred).unique())\n",
    "    print('log_loss:',log_loss(y_test,pred_proba,labels=np.array([0,1,2,3,4,5,6,7,8,9])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "rDpzbqqsjf0M",
    "outputId": "28f63944-e0c4-43ac-c802-0648bb7204c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first with one hot for all\n",
      "lightgbm training with gridsearch\n",
      "accuracy: 0.6151539384246302\n",
      "f1 macro: 0.15983266840796576\n",
      "f1_micro: 0.6151539384246302\n",
      "log_loss: 0.8971268172475173\n",
      "catboost training with gridsearch\n",
      "accuracy: 0.8534586165533786\n",
      "f1 macro: 0.26796949723972613\n",
      "f1_micro: 0.8534586165533786\n",
      "log_loss: 0.4879293372535875\n",
      "xgboost training with gridsearch\n",
      "accuracy: 0.826469412235106\n",
      "f1 macro: 0.19804508633688395\n",
      "f1_micro: 0.826469412235106\n",
      "log_loss: 0.6434038983073692\n",
      "RF training with gridsearch\n",
      "accuracy: 0.5615753698520591\n",
      "f1 macro: 0.12174584182551024\n",
      "f1_micro: 0.5615753698520591\n",
      "log_loss: 0.9486434287651889\n",
      "now with target encoding\n",
      "lightgbm training with gridsearch\n",
      "accuracy: 0.6153538584566174\n",
      "f1 macro: 0.15940669341010638\n",
      "f1_micro: 0.6153538584566174\n",
      "log_loss: 0.8943339722119548\n",
      "catboost training with gridsearch\n",
      "accuracy: 0.8818472610955618\n",
      "f1 macro: 0.2840398868394021\n",
      "f1_micro: 0.8818472610955618\n",
      "log_loss: 0.4474361696112773\n",
      "xgboost training with gridsearch\n",
      "accuracy: 0.8256697321071571\n",
      "f1 macro: 0.1945397454953727\n",
      "f1_micro: 0.8256697321071571\n",
      "log_loss: 0.6409036446609575\n",
      "RF training with gridsearch\n",
      "accuracy: 0.5941623350659736\n",
      "f1 macro: 0.14045002176066346\n",
      "f1_micro: 0.5941623350659736\n",
      "log_loss: 0.9254771350709698\n",
      "now with mix encodings\n",
      "[0, 2, 4, 6, 8] []\n",
      "lightgbm training with gridsearch\n",
      "accuracy: 0.6151539384246302\n",
      "f1 macro: 0.15983266840796576\n",
      "f1_micro: 0.6151539384246302\n",
      "log_loss: 0.8971268172475173\n",
      "catboost training with gridsearch\n",
      "accuracy: 0.8534586165533786\n",
      "f1 macro: 0.26796949723972613\n",
      "f1_micro: 0.8534586165533786\n",
      "log_loss: 0.4879293372535875\n",
      "xgboost training with gridsearch\n",
      "accuracy: 0.826469412235106\n",
      "f1 macro: 0.19804508633688395\n",
      "f1_micro: 0.826469412235106\n",
      "log_loss: 0.6434038983073692\n",
      "RF training with gridsearch\n",
      "accuracy: 0.5559776089564175\n",
      "f1 macro: 0.1186236046682656\n",
      "f1_micro: 0.5559776089564175\n",
      "log_loss: 0.9496203415718345\n",
      "now with native cat features support\n",
      "lightgbm training with gridsearch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nishant\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\nishant\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\nishant\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1295: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [0, 2, 4, 6, 8]\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6193522590963615\n",
      "f1 macro: 0.16028297241303824\n",
      "f1_micro: 0.6193522590963615\n",
      "log_loss: 0.8980715226571092\n",
      "catboost training with gridsearch\n",
      "accuracy: 0.8456617353058776\n",
      "f1 macro: 0.2726260352976164\n",
      "f1_micro: 0.8456617353058776\n",
      "log_loss: 0.5209796047979528\n"
     ]
    }
   ],
   "source": [
    "X=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1:]\n",
    "# X_train,X_test,y_train, y_test=onehot_all(df.iloc[:,:-1],y,.2)\n",
    "# X_train,X_test,y_train, y_test=target_all(df.iloc[:,:-1],y,ratio=.2)\n",
    "# X_train,X_test,y_train, y_test=onehot_target(df.iloc[:,:-1],y,ratio=.2,thresh=10)\n",
    "\n",
    "\n",
    "parameters = {'depth'         : [4,6,8],\n",
    "              'learning_rate' : [.01,.05,.1,.2],\n",
    "              'iterations'    : [100,500]\n",
    "              }\n",
    "# parameters = {'depth'         : [4],\n",
    "#               'learning_rate' : [.2],\n",
    "#               'iterations'    : [50]\n",
    "#               }\n",
    "parameters_xgb = {\n",
    "'n_estimators': [100, 500],\n",
    "    # 'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'learning_rate':[.01,.05,.1,.2],\n",
    "    'max_depth' : [4,6,8],\n",
    "    # 'criterion' :['gini', 'entropy']\n",
    "        }\n",
    "\n",
    "# parameters_xgb = {\n",
    "# 'n_estimators': [50],\n",
    "# #     'max_features': ['auto', 'sqrt', 'log2'],\n",
    "#     'max_depth' : [4],\n",
    "# #     'criterion' :['gini', 'entropy']\n",
    "#         }\n",
    "parameters_RF={'max_depth':[4,6,8], 'n_estimators':[100,500]}\n",
    "\n",
    "print(\"first with one hot for all\")\n",
    "X_train,X_test,y_train, y_test=onehot_all(X,y,.2)\n",
    "train_evaluate( X_train,X_test,y_train, y_test)\n",
    "\n",
    "print(\"now with target encoding\")\n",
    "X_train,X_test,y_train, y_test=target_all(X,y,ratio=.2)\n",
    "train_evaluate( X_train,X_test,y_train, y_test)\n",
    "\n",
    "print(\"now with mix encodings\")\n",
    "X_train,X_test,y_train, y_test=onehot_target(X,y,ratio=.2,thresh=5)\n",
    "train_evaluate( X_train,X_test,y_train, y_test)\n",
    "\n",
    "print(\"now with native cat features support\")\n",
    "\n",
    "X_train,X_test,y_train, y_test=train_test_split(X, y, test_size=.2, random_state=42)\n",
    "train_evaluate_with_cat_feat(X_train,X_test,y_train, y_test,cat_features=list(X_train.select_dtypes('object').columns))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "poker.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
