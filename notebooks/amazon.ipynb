{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8160,
     "status": "ok",
     "timestamp": 1597333397366,
     "user": {
      "displayName": "mohan Nishant",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHg-CY_pw4h3mU1mLqbvv41C1UOT27zwGXlnPS1Q=s64",
      "userId": "04584745754123014335"
     },
     "user_tz": -60
    },
    "id": "ysRIfjyHjfzq",
    "outputId": "44900695-ef9c-4656-b73b-b08cd595a044"
   },
   "outputs": [],
   "source": [
    "# !pip install catboost\n",
    "# !pip install category_encoders\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import OrdinalEncoder,LabelEncoder,OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score,jaccard_score,multilabel_confusion_matrix,log_loss\n",
    "import lightgbm as lgbm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8155,
     "status": "ok",
     "timestamp": 1597333397368,
     "user": {
      "displayName": "mohan Nishant",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHg-CY_pw4h3mU1mLqbvv41C1UOT27zwGXlnPS1Q=s64",
      "userId": "04584745754123014335"
     },
     "user_tz": -60
    },
    "id": "NEm1dWgMkwUz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n",
      "The system cannot find the path specified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403 - Forbidden\n"
     ]
    }
   ],
   "source": [
    "# !mkdir /root/.kaggle\n",
    "# !echo '{\"username\":\"nishmo\",\"key\":\"8e08a450e7fc5f1c616e05ecd6173000\"}' > /root/.kaggle/kaggle.json\n",
    "# !kaggle competitions download -c amazon-employee-access-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8356,
     "status": "ok",
     "timestamp": 1597333397575,
     "user": {
      "displayName": "mohan Nishant",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHg-CY_pw4h3mU1mLqbvv41C1UOT27zwGXlnPS1Q=s64",
      "userId": "04584745754123014335"
     },
     "user_tz": -60
    },
    "id": "xuent7CuvSex"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:/Users/nishant/Desktop/train.csv',dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8345,
     "status": "ok",
     "timestamp": 1597333397576,
     "user": {
      "displayName": "mohan Nishant",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHg-CY_pw4h3mU1mLqbvv41C1UOT27zwGXlnPS1Q=s64",
      "userId": "04584745754123014335"
     },
     "user_tz": -60
    },
    "id": "3Y6hj3ACP3zO",
    "outputId": "fc921b18-e7da-4e15-fdb2-ccb43fa9059e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTION</th>\n",
       "      <th>RESOURCE</th>\n",
       "      <th>MGR_ID</th>\n",
       "      <th>ROLE_ROLLUP_1</th>\n",
       "      <th>ROLE_ROLLUP_2</th>\n",
       "      <th>ROLE_DEPTNAME</th>\n",
       "      <th>ROLE_TITLE</th>\n",
       "      <th>ROLE_FAMILY_DESC</th>\n",
       "      <th>ROLE_FAMILY</th>\n",
       "      <th>ROLE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39353</td>\n",
       "      <td>85475</td>\n",
       "      <td>117961</td>\n",
       "      <td>118300</td>\n",
       "      <td>123472</td>\n",
       "      <td>117905</td>\n",
       "      <td>117906</td>\n",
       "      <td>290919</td>\n",
       "      <td>117908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17183</td>\n",
       "      <td>1540</td>\n",
       "      <td>117961</td>\n",
       "      <td>118343</td>\n",
       "      <td>123125</td>\n",
       "      <td>118536</td>\n",
       "      <td>118536</td>\n",
       "      <td>308574</td>\n",
       "      <td>118539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ACTION RESOURCE MGR_ID ROLE_ROLLUP_1 ROLE_ROLLUP_2 ROLE_DEPTNAME ROLE_TITLE  \\\n",
       "0      1    39353  85475        117961        118300        123472     117905   \n",
       "1      1    17183   1540        117961        118343        123125     118536   \n",
       "\n",
       "  ROLE_FAMILY_DESC ROLE_FAMILY ROLE_CODE  \n",
       "0           117906      290919    117908  \n",
       "1           118536      308574    118539  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8331,
     "status": "ok",
     "timestamp": 1597333397576,
     "user": {
      "displayName": "mohan Nishant",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHg-CY_pw4h3mU1mLqbvv41C1UOT27zwGXlnPS1Q=s64",
      "userId": "04584745754123014335"
     },
     "user_tz": -60
    },
    "id": "ugTL-OPW9syC",
    "outputId": "ccab0084-d6f1-4bf9-c4b8-fc2dff128a07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32769, 10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8320,
     "status": "ok",
     "timestamp": 1597333397577,
     "user": {
      "displayName": "mohan Nishant",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHg-CY_pw4h3mU1mLqbvv41C1UOT27zwGXlnPS1Q=s64",
      "userId": "04584745754123014335"
     },
     "user_tz": -60
    },
    "id": "bIkhjLktmrCC",
    "outputId": "70c1207f-f609-4f77-d18f-b7406abfbae4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ACTION', 'RESOURCE', 'MGR_ID', 'ROLE_ROLLUP_1', 'ROLE_ROLLUP_2',\n",
       "       'ROLE_DEPTNAME', 'ROLE_TITLE', 'ROLE_FAMILY_DESC', 'ROLE_FAMILY',\n",
       "       'ROLE_CODE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8317,
     "status": "ok",
     "timestamp": 1597333397578,
     "user": {
      "displayName": "mohan Nishant",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHg-CY_pw4h3mU1mLqbvv41C1UOT27zwGXlnPS1Q=s64",
      "userId": "04584745754123014335"
     },
     "user_tz": -60
    },
    "id": "C5mhAtvU4wxp"
   },
   "outputs": [],
   "source": [
    "\n",
    "X=df.iloc[:,1:]\n",
    "y=df.iloc[:,0]\n",
    "y=pd.Series(LabelEncoder().fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8307,
     "status": "ok",
     "timestamp": 1597333397580,
     "user": {
      "displayName": "mohan Nishant",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHg-CY_pw4h3mU1mLqbvv41C1UOT27zwGXlnPS1Q=s64",
      "userId": "04584745754123014335"
     },
     "user_tz": -60
    },
    "id": "OfvTqAFaqGKH",
    "outputId": "dafb8729-95dd-4fe0-c3f2-29b5ead24a66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    30872\n",
       "0     1897\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8304,
     "status": "ok",
     "timestamp": 1597333397580,
     "user": {
      "displayName": "mohan Nishant",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHg-CY_pw4h3mU1mLqbvv41C1UOT27zwGXlnPS1Q=s64",
      "userId": "04584745754123014335"
     },
     "user_tz": -60
    },
    "id": "ozYmWD9pjfz4"
   },
   "outputs": [],
   "source": [
    "#label encoder to encode unseen values too\n",
    "class LabelEncoderExt(object):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
    "        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
    "        \"\"\"\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        # self.classes_ = self.label_encoder.classes_\n",
    "\n",
    "    def fit(self, data_list):\n",
    "        \"\"\"\n",
    "        This will fit the encoder for all the unique values and introduce unknown value\n",
    "        :param data_list: A list of string\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
    "        self.classes_ = self.label_encoder.classes_\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_list):\n",
    "        \"\"\"\n",
    "        This will transform the data_list to id list where the new values get assigned to Unknown class\n",
    "        :param data_list:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        new_data_list = list(data_list)\n",
    "        for unique_item in np.unique(data_list):\n",
    "            if unique_item not in self.label_encoder.classes_:\n",
    "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
    "\n",
    "        return self.label_encoder.transform(new_data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8509,
     "status": "ok",
     "timestamp": 1597333397787,
     "user": {
      "displayName": "mohan Nishant",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHg-CY_pw4h3mU1mLqbvv41C1UOT27zwGXlnPS1Q=s64",
      "userId": "04584745754123014335"
     },
     "user_tz": -60
    },
    "id": "6PbWO133jfz8"
   },
   "outputs": [],
   "source": [
    "#encodings and split\n",
    "\n",
    "def onehot_all(X,y,ratio):\n",
    "    \n",
    "    #split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=42)\n",
    "    \n",
    "    obj_cols=X.select_dtypes('object').columns\n",
    "    enc=ce.OneHotEncoder(cols=obj_cols,handle_missing='return_nan').fit(X_train,y_train)\n",
    "    X_train=enc.transform(X_train)\n",
    "    X_test=enc.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test,y_train, y_test\n",
    "\n",
    "def target_all(X,y,ratio):\n",
    "    \n",
    "    #split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=42)\n",
    "    \n",
    "#     obj_cols=X.select_dtypes('object').columns\n",
    "    enc=ce.TargetEncoder(handle_missing='return_nan').fit(X_train,y_train)\n",
    "    X_train=enc.transform(X_train)\n",
    "    X_test=enc.transform(X_test)\n",
    "    \n",
    "    return X_train,X_test,y_train, y_test\n",
    "    \n",
    "def onehot_target(X,y,ratio,thresh):\n",
    "    \n",
    "    #split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=42)\n",
    "    \n",
    "    low_card_cols,high_card_cols=[],[]\n",
    "    obj_cols=X.select_dtypes('object').columns\n",
    "    for col in obj_cols:\n",
    "        if X_train[col].nunique()<=thresh:\n",
    "            low_card_cols.append(col)\n",
    "        else:\n",
    "            high_card_cols.append(col)\n",
    "    \n",
    "    print(low_card_cols,high_card_cols)\n",
    "    \n",
    "    enc=ce.OneHotEncoder(cols=low_card_cols,handle_missing='return_nan').fit(X_train,y_train)\n",
    "    X_train=enc.transform(X_train)\n",
    "    X_test=enc.transform(X_test)\n",
    "    \n",
    "    enc=ce.TargetEncoder(cols=high_card_cols,handle_missing='return_nan').fit(X_train,y_train)\n",
    "    X_train=enc.transform(X_train)\n",
    "    X_test=enc.transform(X_test)\n",
    "    \n",
    "    return X_train,X_test,y_train, y_test\n",
    "\n",
    "def target_encode_multiclass(X,y,ratio):\n",
    "    # class_names=y.unique()\n",
    "    # y_classes=pd.DataFrame(columns=class_names)\n",
    "\n",
    "    # for class_ in class_names:\n",
    "    #   y_class_=y.map(lambda x: 1 if x==class_ else 0)\n",
    "    #   y_classes[class_]=y_class_\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y.astype(str), test_size=ratio, random_state=42)\n",
    "\n",
    "    enc=ce.OneHotEncoder().fit(y_train)\n",
    "    y_train_onehot=enc.transform(y_train)\n",
    "    y_test_onehot=enc.transform(y_test)\n",
    "    class_names=y_train_onehot.columns\n",
    "\n",
    "    X_train_obj=X_train.select_dtypes('object')\n",
    "    X_test_obj=X_test.select_dtypes('object')\n",
    "    X_train=X_train.select_dtypes(exclude='object')\n",
    "    X_test=X_test.select_dtypes(exclude='object')\n",
    "\n",
    "    for class_ in class_names:\n",
    "      \n",
    "      enc=ce.TargetEncoder(handle_missing='return_nan').fit(X_train_obj,y_train_onehot[class_])\n",
    "      temp=enc.transform(X_train_obj)\n",
    "      temp.columns=[str(x)+'_'+str(class_) for x in temp.columns]\n",
    "      X_train=pd.concat([X_train,temp],axis=1)\n",
    "      temp=enc.transform(X_test_obj)\n",
    "      temp.columns=[str(x)+'_'+str(class_) for x in temp.columns]\n",
    "      X_test=pd.concat([X_test,temp],axis=1)\n",
    "      \n",
    "    return X_train, X_test, y_train.astype(int), y_test.astype(int)\n",
    "\n",
    "def onehot_target_encode_multiclass(X,y,ratio,thresh):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y.astype(str), test_size=ratio, random_state=42)\n",
    "\n",
    "    low_card_cols,high_card_cols=[],[]\n",
    "    obj_cols=X.select_dtypes('object').columns\n",
    "    for col in obj_cols:\n",
    "        if X_train[col].nunique()<=thresh:\n",
    "            low_card_cols.append(col)\n",
    "        else:\n",
    "            high_card_cols.append(col)\n",
    "    \n",
    "    enc=ce.OneHotEncoder(cols=low_card_cols,handle_missing='return_nan').fit(X_train,y_train)\n",
    "    X_train=enc.transform(X_train)\n",
    "    X_test=enc.transform(X_test)\n",
    "\n",
    "    enc=ce.OneHotEncoder().fit(y_train)\n",
    "    y_train_onehot=enc.transform(y_train)\n",
    "    y_test_onehot=enc.transform(y_test)\n",
    "    class_names=y_train_onehot.columns\n",
    "\n",
    "    X_train_obj=X_train.select_dtypes('object')\n",
    "    X_test_obj=X_test.select_dtypes('object')\n",
    "    X_train=X_train.select_dtypes(exclude='object')\n",
    "    X_test=X_test.select_dtypes(exclude='object')\n",
    "\n",
    "    for class_ in class_names:\n",
    "      \n",
    "      enc=ce.TargetEncoder(handle_missing='return_nan').fit(X_train_obj,y_train_onehot[class_])\n",
    "      temp=enc.transform(X_train_obj)\n",
    "      temp.columns=[str(x)+'_'+str(class_) for x in temp.columns]\n",
    "      X_train=pd.concat([X_train,temp],axis=1)\n",
    "      temp=enc.transform(X_test_obj)\n",
    "      temp.columns=[str(x)+'_'+str(class_) for x in temp.columns]\n",
    "      X_test=pd.concat([X_test,temp],axis=1)\n",
    "      \n",
    "    return X_train, X_test, y_train.astype(int), y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8507,
     "status": "ok",
     "timestamp": 1597333397788,
     "user": {
      "displayName": "mohan Nishant",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHg-CY_pw4h3mU1mLqbvv41C1UOT27zwGXlnPS1Q=s64",
      "userId": "04584745754123014335"
     },
     "user_tz": -60
    },
    "id": "oH6nIrLBMmCS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8504,
     "status": "ok",
     "timestamp": 1597333397789,
     "user": {
      "displayName": "mohan Nishant",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHg-CY_pw4h3mU1mLqbvv41C1UOT27zwGXlnPS1Q=s64",
      "userId": "04584745754123014335"
     },
     "user_tz": -60
    },
    "id": "EmAQA0NNjfz_"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_evaluate( X_train,X_test,y_train, y_test,encoding):\n",
    "\n",
    "  # try:\n",
    "  print(\"lightgbm training with gridsearch\")\n",
    "\n",
    "  model = lgbm.LGBMClassifier(boosting_type='goss')\n",
    "  grid = GridSearchCV(estimator=model, param_grid = parameters)\n",
    "  grid.fit(X_train, y_train,verbose=0)    \n",
    "\n",
    "  model=grid.best_estimator_\n",
    "  evaluate(model,X_test,y_test,encoding)\n",
    "  # except: pass\n",
    "\n",
    "  try:\n",
    "    print(\"xgboost training with gridsearch\")\n",
    "\n",
    "    model = XGBClassifier(tree_method='gpu_hist', gpu_id=0)\n",
    "    grid = GridSearchCV(estimator=model, param_grid = parameters_xgb)\n",
    "    grid.fit(X_train, y_train,verbose=0)    \n",
    "\n",
    "    model=grid.best_estimator_\n",
    "    evaluate(model,X_test,y_test,encoding)\n",
    "  except:pass\n",
    "\n",
    "  try:  \n",
    "    print(\"RF training with gridsearch\")\n",
    "    \n",
    "    model=RandomForestClassifier()\n",
    "    grid = GridSearchCV(estimator=model, param_grid = parameters_RF)\n",
    "    grid.fit(X_train.fillna(value=0), y_train)    \n",
    "\n",
    "    model=grid.best_estimator_\n",
    "    evaluate(model,X_test.fillna(value=0),y_test,encoding)\n",
    "  except:pass\n",
    "    \n",
    "\n",
    "  try:\n",
    "    print(\"catboost training with gridsearch\")\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        task_type=\"GPU\", devices='0:1'\n",
    "    )\n",
    "    grid = GridSearchCV(estimator=model, param_grid = parameters)\n",
    "    grid.fit(X_train, y_train,verbose=0)    \n",
    "\n",
    "    model=grid.best_estimator_\n",
    "    evaluate(model,X_test,y_test,encoding)\n",
    "  except:pass\n",
    "\n",
    "def train_evaluate_with_cat_feat( X_train,X_test,y_train, y_test,cat_features,encoding):\n",
    "  try:\n",
    "    print(\"lightgbm training with gridsearch\")\n",
    "    for col in cat_features:\n",
    "        le = LabelEncoderExt()\n",
    "        le.fit(X_train[col])\n",
    "        X_train[col]=le.transform(X_train[col])\n",
    "        X_test[col]=le.transform(X_test[col])\n",
    "\n",
    "    fit_params={'categorical_feature':cat_features}\n",
    "    model = lgbm.LGBMClassifier(boosting_type='goss')\n",
    "    grid = GridSearchCV(estimator=model, param_grid = parameters)\n",
    "    grid.fit(X_train, y_train,verbose=0,**fit_params)    \n",
    "\n",
    "    model=grid.best_estimator_\n",
    "    evaluate(model,X_test,y_test,encoding)\n",
    "  except:pass\n",
    "\n",
    "  try:\n",
    "    print(\"catboost training with gridsearch\")\n",
    "    fit_params={'cat_features':cat_features}\n",
    "    model = CatBoostClassifier(\n",
    "        task_type=\"GPU\", devices='0:1'\n",
    "    )\n",
    "    grid = GridSearchCV(estimator=model, param_grid = parameters)\n",
    "    grid.fit(X_train, y_train,verbose=0,**fit_params)    \n",
    "\n",
    "    model=grid.best_estimator_\n",
    "    evaluate(model,X_test,y_test,encoding)\n",
    "  except:pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8502,
     "status": "ok",
     "timestamp": 1597333397790,
     "user": {
      "displayName": "mohan Nishant",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiHg-CY_pw4h3mU1mLqbvv41C1UOT27zwGXlnPS1Q=s64",
      "userId": "04584745754123014335"
     },
     "user_tz": -60
    },
    "id": "T8lipuKDjf0D"
   },
   "outputs": [],
   "source": [
    "#evaluation function\n",
    "\n",
    "# def evaluate(model,X_test,y_test):\n",
    "    \n",
    "#     pred=model.predict(X_test)\n",
    "#     pred_proba=model.predict_proba(X_test)\n",
    "#     # print(pd.Series(pred).value_counts())\n",
    "#     print('accuracy:',accuracy_score(y_test,pred))\n",
    "#     print('f1 macro:',f1_score(y_test,pred, average='macro'))\n",
    "#     # print('f1_micro:',f1_score(y_test,pred, average='micro'))\n",
    "# #     print(pd.Series(pred).unique())\n",
    "#     print('log_loss:',log_loss(y_test,pred_proba,labels=[i for i in range(10)]))\n",
    "def evaluate(model,X_test,y_test,encoding):\n",
    "    results=pd.read_csv('amazon.csv')\n",
    "\n",
    "    pred=model.predict(X_test)\n",
    "    pred_proba=model.predict_proba(X_test)\n",
    "    \n",
    "    mod=model\n",
    "    acc=accuracy_score(y_test,pred)\n",
    "    f1=f1_score(y_test,pred, average='macro')\n",
    "    loss=log_loss(y_test,pred_proba)\n",
    "    cols=list(X_test.columns)\n",
    "    imp=list(permutation_importance(model,X_test,y_test)['importances_mean'])\n",
    "    \n",
    "    print('accuracy:',acc)\n",
    "    print('f1 macro:',f1)\n",
    "    # print('f1_micro:',f1_score(y_test,pred, average='micro'))\n",
    "#     print(pd.Series(pred).unique())\n",
    "    print('log_loss:',loss)\n",
    "\n",
    "    result_this=pd.Series({'encoding':encoding,'model':mod, 'accuracy':acc, 'f1':f1, 'loss':loss, 'cols':cols, 'importance':imp})\n",
    "    results=results.append(result_this,ignore_index=True)\n",
    "    results.to_csv('amazon.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "rDpzbqqsjf0M",
    "outputId": "a76c1aac-f4dd-4d5f-a974-0340578e5c9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "now with one hot for all\n",
      "lightgbm training with gridsearch\n"
     ]
    }
   ],
   "source": [
    "# X=df.iloc[:,:-1]\n",
    "# y=df.iloc[:,-1:]\n",
    "# X_train,X_test,y_train, y_test=onehot_all(df.iloc[:,:-1],y,.2)\n",
    "# X_train,X_test,y_train, y_test=target_all(df.iloc[:,:-1],y,ratio=.2)\n",
    "# X_train,X_test,y_train, y_test=onehot_target(df.iloc[:,:-1],y,ratio=.2,thresh=10)\n",
    "\n",
    "\n",
    "parameters = {'depth'         : [6,8],\n",
    "              'learning_rate' : [.01,.05,.1,.2],\n",
    "              'n_estimators': [200],\n",
    "              # 'reg_lambda': [0,0.5,1.0]\n",
    "              # 'iterations'    : [500,1000,2000]\n",
    "              }\n",
    "# parameters = {\n",
    "# #     'depth'         : [4],\n",
    "# #               'learning_rate' : [.2],\n",
    "#               'iterations'    : [50]\n",
    "#               }\n",
    "parameters_xgb = {\n",
    "'n_estimators': [500],\n",
    "    # 'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [6,8],\n",
    "    # 'criterion' :['gini', 'entropy'],\n",
    "    # 'reg_lambda': [0,0.5,1.0]\n",
    "        }\n",
    "\n",
    "# parameters_xgb = {\n",
    "# # 'n_estimators': [50],\n",
    "# #     'max_features': ['auto', 'sqrt', 'log2'],\n",
    "# #     'max_depth' : [4],\n",
    "# #     'criterion' :['gini', 'entropy']\n",
    "#         }\n",
    "parameters_RF={\n",
    "    'max_depth':[6,8], 'n_estimators':[500]\n",
    "}\n",
    "# parameters_RF={'max_depth':[2], 'n_estimators':[10]}\n",
    "\n",
    "try:\n",
    "  results=pd.read_csv('amazon.csv')\n",
    "except:\n",
    "  results=pd.DataFrame(columns=['encoding','model','accuracy','f1','loss','cols','importance'])\n",
    "  results.to_csv('amazon.csv')\n",
    "\n",
    "# print(\"##############################\")\n",
    "# print(\"now with target for all\")\n",
    "# X_train,X_test,y_train, y_test=target_encode_multiclass(X,y,.3)\n",
    "# train_evaluate( X_train,X_test,y_train, y_test, encoding='target')\n",
    "# print(\"##############################\")\n",
    "# print(\"now with mixed for all\")\n",
    "# X_train,X_test,y_train, y_test=onehot_target_encode_multiclass(X,y,.2,8)\n",
    "# train_evaluate( X_train,X_test,y_train, y_test,encoding='mixed')\n",
    "# print(\"##############################\")\n",
    "# print(\"now with native cat features support\")\n",
    "# X_train,X_test,y_train, y_test=train_test_split(X, y, test_size=.2, random_state=42)\n",
    "# train_evaluate_with_cat_feat(X_train,X_test,y_train, y_test,cat_features=list(X_train.select_dtypes('object').columns),encoding='native')\n",
    "print(\"##############################\")\n",
    "print(\"now with one hot for all\")\n",
    "X_train,X_test,y_train, y_test=onehot_all(X,y,.2)\n",
    "train_evaluate( X_train,X_test,y_train, y_test,encoding='onehot')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "amazon.ipynb",
   "provenance": [
    {
     "file_id": "1Dd3idq5po-KeypHNg1BDfIRu7ECs02BB",
     "timestamp": 1597219557641
    },
    {
     "file_id": "1c_Fyg1MzKkdgB9ovsKFXLnKSunc75nZQ",
     "timestamp": 1596384967323
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
