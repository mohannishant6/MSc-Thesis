{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "colab_type": "code",
    "id": "ysRIfjyHjfzq",
    "outputId": "0f26580d-8653-4d15-ddcb-0f93a22f42b3"
   },
   "outputs": [],
   "source": [
    "# !pip install catboost\n",
    "# !pip install category_encoders\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import OrdinalEncoder,LabelEncoder,OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score,jaccard_score,multilabel_confusion_matrix,log_loss\n",
    "import lightgbm as lgbm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6zn1R7MfP2Nx"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../land_prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "3Y6hj3ACP3zO",
    "outputId": "2d962311-b753-4ecd-93f7-7e6948209485"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>LandCategory</th>\n",
       "      <th>Region</th>\n",
       "      <th>Region or State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Acre Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Northeast</td>\n",
       "      <td>Farm Real Estate</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>Region</td>\n",
       "      <td>1997</td>\n",
       "      <td>2240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Farm Real Estate</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>State</td>\n",
       "      <td>1997</td>\n",
       "      <td>5950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>Farm Real Estate</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>State</td>\n",
       "      <td>1997</td>\n",
       "      <td>2580.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maine</td>\n",
       "      <td>Farm Real Estate</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>State</td>\n",
       "      <td>1997</td>\n",
       "      <td>1170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>Farm Real Estate</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>State</td>\n",
       "      <td>1997</td>\n",
       "      <td>3150.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         State      LandCategory     Region Region or State  Year  Acre Value\n",
       "0    Northeast  Farm Real Estate  Northeast          Region  1997      2240.0\n",
       "1  Connecticut  Farm Real Estate  Northeast           State  1997      5950.0\n",
       "2     Delaware  Farm Real Estate  Northeast           State  1997      2580.0\n",
       "3        Maine  Farm Real Estate  Northeast           State  1997      1170.0\n",
       "4     Maryland  Farm Real Estate  Northeast           State  1997      3150.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RDrb2b1Fcij8"
   },
   "outputs": [],
   "source": [
    "\n",
    "df.dropna(inplace=True)\n",
    "df['Acre Value']=pd.Series(pd.cut(df.iloc[:,-1],2)).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C5mhAtvU4wxp"
   },
   "outputs": [],
   "source": [
    "X=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "y=pd.Series(LabelEncoder().fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ozYmWD9pjfz4"
   },
   "outputs": [],
   "source": [
    "#label encoder to encode unseen values too\n",
    "class LabelEncoderExt(object):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
    "        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
    "        \"\"\"\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        # self.classes_ = self.label_encoder.classes_\n",
    "\n",
    "    def fit(self, data_list):\n",
    "        \"\"\"\n",
    "        This will fit the encoder for all the unique values and introduce unknown value\n",
    "        :param data_list: A list of string\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
    "        self.classes_ = self.label_encoder.classes_\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_list):\n",
    "        \"\"\"\n",
    "        This will transform the data_list to id list where the new values get assigned to Unknown class\n",
    "        :param data_list:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        new_data_list = list(data_list)\n",
    "        for unique_item in np.unique(data_list):\n",
    "            if unique_item not in self.label_encoder.classes_:\n",
    "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
    "\n",
    "        return self.label_encoder.transform(new_data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6PbWO133jfz8"
   },
   "outputs": [],
   "source": [
    "#encodings and split\n",
    "\n",
    "def onehot_all(X,y,ratio):\n",
    "    \n",
    "    #split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=42)\n",
    "    \n",
    "    obj_cols=X.select_dtypes('object').columns\n",
    "    enc=ce.OneHotEncoder(cols=obj_cols,handle_missing='return_nan').fit(X_train,y_train)\n",
    "    X_train=enc.transform(X_train)\n",
    "    X_test=enc.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test,y_train, y_test\n",
    "\n",
    "def target_all(X,y,ratio):\n",
    "    \n",
    "    #split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=42)\n",
    "    \n",
    "#     obj_cols=X.select_dtypes('object').columns\n",
    "    enc=ce.TargetEncoder(handle_missing='return_nan').fit(X_train,y_train)\n",
    "    X_train=enc.transform(X_train)\n",
    "    X_test=enc.transform(X_test)\n",
    "    \n",
    "    return X_train,X_test,y_train, y_test\n",
    "    \n",
    "def onehot_target(X,y,ratio,thresh):\n",
    "    \n",
    "    #split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=42)\n",
    "    \n",
    "    low_card_cols,high_card_cols=[],[]\n",
    "    obj_cols=X.select_dtypes('object').columns\n",
    "    for col in obj_cols:\n",
    "        if X_train[col].nunique()<=thresh:\n",
    "            low_card_cols.append(col)\n",
    "        else:\n",
    "            high_card_cols.append(col)\n",
    "    \n",
    "    print(low_card_cols,high_card_cols)\n",
    "    \n",
    "    enc=ce.OneHotEncoder(cols=low_card_cols,handle_missing='return_nan').fit(X_train,y_train)\n",
    "    X_train=enc.transform(X_train)\n",
    "    X_test=enc.transform(X_test)\n",
    "    \n",
    "    enc=ce.TargetEncoder(cols=high_card_cols,handle_missing='return_nan').fit(X_train,y_train)\n",
    "    X_train=enc.transform(X_train)\n",
    "    X_test=enc.transform(X_test)\n",
    "    \n",
    "    return X_train,X_test,y_train, y_test\n",
    "\n",
    "def target_encode_multiclass(X,y,ratio):\n",
    "    # class_names=y.unique()\n",
    "    # y_classes=pd.DataFrame(columns=class_names)\n",
    "\n",
    "    # for class_ in class_names:\n",
    "    #   y_class_=y.map(lambda x: 1 if x==class_ else 0)\n",
    "    #   y_classes[class_]=y_class_\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y.astype(str), test_size=ratio, random_state=42)\n",
    "\n",
    "    enc=ce.OneHotEncoder().fit(y_train)\n",
    "    y_train_onehot=enc.transform(y_train)\n",
    "    y_test_onehot=enc.transform(y_test)\n",
    "    class_names=y_train_onehot.columns\n",
    "\n",
    "    X_train_obj=X_train.select_dtypes('object')\n",
    "    X_test_obj=X_test.select_dtypes('object')\n",
    "    X_train=X_train.select_dtypes(exclude='object')\n",
    "    X_test=X_test.select_dtypes(exclude='object')\n",
    "\n",
    "    for class_ in class_names:\n",
    "      \n",
    "      enc=ce.TargetEncoder(handle_missing='return_nan').fit(X_train_obj,y_train_onehot[class_])\n",
    "      temp=enc.transform(X_train_obj)\n",
    "      temp.columns=[str(x)+'_'+str(class_) for x in temp.columns]\n",
    "      X_train=pd.concat([X_train,temp],axis=1)\n",
    "      temp=enc.transform(X_test_obj)\n",
    "      temp.columns=[str(x)+'_'+str(class_) for x in temp.columns]\n",
    "      X_test=pd.concat([X_test,temp],axis=1)\n",
    "      \n",
    "    return X_train, X_test, y_train.astype(int), y_test.astype(int)\n",
    "\n",
    "def onehot_target_encode_multiclass(X,y,ratio,thresh):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y.astype(str), test_size=ratio, random_state=42)\n",
    "\n",
    "    low_card_cols,high_card_cols=[],[]\n",
    "    obj_cols=X.select_dtypes('object').columns\n",
    "    for col in obj_cols:\n",
    "        if X_train[col].nunique()<=thresh:\n",
    "            low_card_cols.append(col)\n",
    "        else:\n",
    "            high_card_cols.append(col)\n",
    "    \n",
    "    enc=ce.OneHotEncoder(cols=low_card_cols,handle_missing='return_nan').fit(X_train,y_train)\n",
    "    X_train=enc.transform(X_train)\n",
    "    X_test=enc.transform(X_test)\n",
    "\n",
    "    enc=ce.OneHotEncoder().fit(y_train)\n",
    "    y_train_onehot=enc.transform(y_train)\n",
    "    y_test_onehot=enc.transform(y_test)\n",
    "    class_names=y_train_onehot.columns\n",
    "\n",
    "    X_train_obj=X_train.select_dtypes('object')\n",
    "    X_test_obj=X_test.select_dtypes('object')\n",
    "    X_train=X_train.select_dtypes(exclude='object')\n",
    "    X_test=X_test.select_dtypes(exclude='object')\n",
    "\n",
    "    for class_ in class_names:\n",
    "      \n",
    "      enc=ce.TargetEncoder(handle_missing='return_nan').fit(X_train_obj,y_train_onehot[class_])\n",
    "      temp=enc.transform(X_train_obj)\n",
    "      temp.columns=[str(x)+'_'+str(class_) for x in temp.columns]\n",
    "      X_train=pd.concat([X_train,temp],axis=1)\n",
    "      temp=enc.transform(X_test_obj)\n",
    "      temp.columns=[str(x)+'_'+str(class_) for x in temp.columns]\n",
    "      X_test=pd.concat([X_test,temp],axis=1)\n",
    "      \n",
    "    return X_train, X_test, y_train.astype(int), y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oH6nIrLBMmCS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EmAQA0NNjfz_"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_evaluate( X_train,X_test,y_train, y_test,encoding):\n",
    "\n",
    "  # try:\n",
    "  print(\"lightgbm training with gridsearch\")\n",
    "\n",
    "  model = lgbm.LGBMClassifier(boosting_type='goss')\n",
    "  grid = GridSearchCV(estimator=model, param_grid = parameters)\n",
    "  grid.fit(X_train, y_train,verbose=0)    \n",
    "\n",
    "  model=grid.best_estimator_\n",
    "  evaluate(model,X_test,y_test,encoding)\n",
    "  # except: pass\n",
    "\n",
    "  try:\n",
    "    print(\"catboost training with gridsearch\")\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        task_type=\"GPU\", devices='0:1'\n",
    "    )\n",
    "    grid = GridSearchCV(estimator=model, param_grid = parameters)\n",
    "    grid.fit(X_train, y_train,verbose=0)    \n",
    "\n",
    "    model=grid.best_estimator_\n",
    "    evaluate(model,X_test,y_test,encoding)\n",
    "  except:pass\n",
    "\n",
    "  try:\n",
    "    print(\"xgboost training with gridsearch\")\n",
    "\n",
    "    model = XGBClassifier(tree_method='gpu_hist', gpu_id=0)\n",
    "    grid = GridSearchCV(estimator=model, param_grid = parameters_xgb)\n",
    "    grid.fit(X_train, y_train,verbose=0)    \n",
    "\n",
    "    model=grid.best_estimator_\n",
    "    evaluate(model,X_test,y_test,encoding)\n",
    "  except:pass\n",
    "\n",
    "  try:  \n",
    "    print(\"RF training with gridsearch\")\n",
    "    \n",
    "    model=RandomForestClassifier()\n",
    "    grid = GridSearchCV(estimator=model, param_grid = parameters_RF)\n",
    "    grid.fit(X_train.fillna(value=0), y_train)    \n",
    "\n",
    "    model=grid.best_estimator_\n",
    "    evaluate(model,X_test.fillna(value=0),y_test,encoding)\n",
    "  except:pass\n",
    "    \n",
    "def train_evaluate_with_cat_feat( X_train,X_test,y_train, y_test,cat_features=None):\n",
    "  try:\n",
    "    print(\"lightgbm training with gridsearch\")\n",
    "    for col in cat_features:\n",
    "        le = LabelEncoderExt()\n",
    "        le.fit(X_train[col])\n",
    "        X_train[col]=le.transform(X_train[col])\n",
    "        X_test[col]=le.transform(X_test[col])\n",
    "\n",
    "    fit_params={'categorical_feature':cat_features}\n",
    "    model = lgbm.LGBMClassifier(boosting_type='goss')\n",
    "    grid = GridSearchCV(estimator=model, param_grid = parameters)\n",
    "    grid.fit(X_train, y_train,verbose=0,**fit_params)    \n",
    "\n",
    "    model=grid.best_estimator_\n",
    "    evaluate(model,X_test,y_test,encoding)\n",
    "  except:pass\n",
    "\n",
    "  try:\n",
    "    print(\"catboost training with gridsearch\")\n",
    "    fit_params={'cat_features':cat_features}\n",
    "    model = CatBoostClassifier(\n",
    "        task_type=\"GPU\", devices='0:1'\n",
    "    )\n",
    "    grid = GridSearchCV(estimator=model, param_grid = parameters)\n",
    "    grid.fit(X_train, y_train,verbose=0,**fit_params)    \n",
    "\n",
    "    model=grid.best_estimator_\n",
    "    evaluate(model,X_test,y_test,encoding)\n",
    "  except:pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T8lipuKDjf0D"
   },
   "outputs": [],
   "source": [
    "#evaluation function\n",
    "\n",
    "# def evaluate(model,X_test,y_test):\n",
    "    \n",
    "#     pred=model.predict(X_test)\n",
    "#     pred_proba=model.predict_proba(X_test)\n",
    "#     # print(pd.Series(pred).value_counts())\n",
    "#     print('accuracy:',accuracy_score(y_test,pred))\n",
    "#     print('f1 macro:',f1_score(y_test,pred, average='macro'))\n",
    "#     # print('f1_micro:',f1_score(y_test,pred, average='micro'))\n",
    "# #     print(pd.Series(pred).unique())\n",
    "#     print('log_loss:',log_loss(y_test,pred_proba,labels=[i for i in range(10)]))\n",
    "def evaluate(model,X_test,y_test,encoding):\n",
    "    global results\n",
    "    pred=model.predict(X_test)\n",
    "    pred_proba=model.predict_proba(X_test)\n",
    "    \n",
    "    mod=model\n",
    "    acc=accuracy_score(y_test,pred)\n",
    "    f1=f1_score(y_test,pred, average='macro')\n",
    "    loss=log_loss(y_test,pred_proba,labels=[i for i in range(2)])\n",
    "    cols=list(X_test.columns)\n",
    "    imp=list(permutation_importance(model,X_test,y_test)['importances_mean'])\n",
    "    \n",
    "    print('accuracy:',acc)\n",
    "    print('f1 macro:',f1)\n",
    "    # print('f1_micro:',f1_score(y_test,pred, average='micro'))\n",
    "#     print(pd.Series(pred).unique())\n",
    "    print('log_loss:',loss)\n",
    "\n",
    "    result_this=pd.Series({'encoding':encoding,'model':mod, 'accuracy':acc, 'f1':f1, 'loss':loss, 'cols':cols, 'importance':imp})\n",
    "    results=results.append(result_this,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "colab_type": "code",
    "id": "vcmqfikmdE8a",
    "outputId": "84779f80-e466-49d6-b67e-957ae2c4d4f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "now with target for all\n",
      "lightgbm training with gridsearch\n",
      "accuracy: 0.9922928709055877\n",
      "f1 macro: 0.9453684210526316\n",
      "log_loss: 0.03762231754588973\n",
      "catboost training with gridsearch\n",
      "accuracy: 0.9913294797687862\n",
      "f1 macro: 0.9393073159956602\n",
      "log_loss: 0.033443797770118154\n",
      "xgboost training with gridsearch\n",
      "accuracy: 0.9913294797687862\n",
      "f1 macro: 0.9407845946134392\n",
      "log_loss: 0.03427115390787866\n",
      "RF training with gridsearch\n",
      "accuracy: 0.9922928709055877\n",
      "f1 macro: 0.9453684210526316\n",
      "log_loss: 0.07878869399311096\n",
      "##############################\n",
      "now with mixed for all\n",
      "lightgbm training with gridsearch\n",
      "accuracy: 0.9884393063583815\n",
      "f1 macro: 0.8970238095238094\n",
      "log_loss: 0.04934726402698487\n",
      "catboost training with gridsearch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% gpu memory available for training. Free: 981.3031244 Total: 2048\n",
      "Warning: less than 75% gpu memory available for training. Free: 981.3031244 Total: 2048\n",
      "Warning: less than 75% gpu memory available for training. Free: 981.3031244 Total: 2048\n",
      "Warning: less than 75% gpu memory available for training. Free: 981.3031244 Total: 2048\n",
      "Warning: less than 75% gpu memory available for training. Free: 981.3031244 Total: 2048\n",
      "Warning: less than 75% gpu memory available for training. Free: 981.3031244 Total: 2048\n"
     ]
    }
   ],
   "source": [
    "# X=df.iloc[:,:-1]\n",
    "# y=df.iloc[:,-1:]\n",
    "# X_train,X_test,y_train, y_test=onehot_all(df.iloc[:,:-1],y,.2)\n",
    "# X_train,X_test,y_train, y_test=target_all(df.iloc[:,:-1],y,ratio=.2)\n",
    "# X_train,X_test,y_train, y_test=onehot_target(df.iloc[:,:-1],y,ratio=.2,thresh=10)\n",
    "\n",
    "\n",
    "# parameters = {'depth'         : [6,8,10],\n",
    "#               'learning_rate' : [.01,.05,.1,.2],\n",
    "#               'n_estimators': [500,1000],\n",
    "#               # 'reg_lambda': [0,0.5,1.0]\n",
    "#               # 'iterations'    : [500,1000,2000]\n",
    "#               }\n",
    "parameters = {\n",
    "#     'depth'         : [4],\n",
    "#               'learning_rate' : [.2],\n",
    "              'iterations'    : [50]\n",
    "              }\n",
    "# parameters_xgb = {\n",
    "# 'n_estimators': [500,1000],\n",
    "#     # 'max_features': ['auto', 'sqrt', 'log2'],\n",
    "#     'max_depth' : [6,8,10],\n",
    "#     'criterion' :['gini', 'entropy'],\n",
    "#     # 'reg_lambda': [0,0.5,1.0]\n",
    "#         }\n",
    "\n",
    "parameters_xgb = {\n",
    "# 'n_estimators': [50],\n",
    "#     'max_features': ['auto', 'sqrt', 'log2'],\n",
    "#     'max_depth' : [4],\n",
    "#     'criterion' :['gini', 'entropy']\n",
    "        }\n",
    "parameters_RF={\n",
    "#     'max_depth':[6,8,10], 'n_estimators':[500,1000]\n",
    "}\n",
    "# parameters_RF={'max_depth':[2], 'n_estimators':[10]}\n",
    "\n",
    "results=pd.DataFrame(columns=['encoding','model','accuracy','f1','loss','cols','importance'])\n",
    "\n",
    "print(\"##############################\")\n",
    "print(\"now with target for all\")\n",
    "X_train,X_test,y_train, y_test=target_encode_multiclass(X,y,.3)\n",
    "train_evaluate( X_train,X_test,y_train, y_test, encoding='target')\n",
    "print(\"##############################\")\n",
    "print(\"now with mixed for all\")\n",
    "X_train,X_test,y_train, y_test=onehot_target_encode_multiclass(X,y,.2,8)\n",
    "train_evaluate( X_train,X_test,y_train, y_test,encoding='mixed')\n",
    "print(\"##############################\")\n",
    "print(\"now with one hot for all\")\n",
    "X_train,X_test,y_train, y_test=onehot_all(X,y,.2)\n",
    "train_evaluate( X_train,X_test,y_train, y_test,encoding='onehot')\n",
    "print(\"##############################\")\n",
    "print(\"now with native cat features support\")\n",
    "X_train,X_test,y_train, y_test=train_test_split(X, y, test_size=.2, random_state=42)\n",
    "train_evaluate_with_cat_feat(X_train,X_test,y_train, y_test,cat_features=list(X_train.select_dtypes('object').columns),encoding='native')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train, y_test=onehot_all(X,y,.2)\n",
    "# for col in list(X_train.select_dtypes('object').columns):\n",
    "#     le = LabelEncoderExt()\n",
    "#     le.fit(X_train[col])\n",
    "#     X_train[col]=le.transform(X_train[col])\n",
    "#     X_test[col]=le.transform(X_test[col])\n",
    "\n",
    "model = lgbm.LGBMClassifier()\n",
    "# CatBoostClassifier(task_type=\"GPU\", devices='0:1')\n",
    "# lgbm.LGBMClassifier()\n",
    "# RandomForestClassifier()\n",
    "# XGBClassifier(tree_method='gpu_hist', gpu_id=0)\n",
    "model.fit(X_train, y_train\n",
    "          ,verbose=0\n",
    "#           ,eval_set=(X_test,y_test)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in res:\n",
    "    res[key]=str(res[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=results.append(res,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "land_prices.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
