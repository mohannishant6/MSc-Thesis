{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "contraceptive.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysRIfjyHjfzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "c28b879a-4378-4a7e-fde0-fecaabaec948"
      },
      "source": [
        "!pip install catboost\n",
        "!pip install category_encoders\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "import category_encoders as ce\n",
        "from sklearn.preprocessing import OrdinalEncoder,LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score,jaccard_score,multilabel_confusion_matrix,log_loss\n",
        "import lightgbm as lgbm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from sklearn.exceptions import DataConversionWarning\n",
        "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.6/dist-packages (0.23.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.12.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.6/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.18.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5.1->category_encoders) (1.12.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1shihhTiyCXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/cmc/cmc.data',header=None)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef6NlyjmvDUY",
        "colab_type": "text"
      },
      "source": [
        "Attribute Information:\n",
        "\n",
        "0. Wife's age (numerical)\n",
        "1. Wife's education (categorical) 1=low, 2, 3, 4=high\n",
        "2. Husband's education (categorical) 1=low, 2, 3, 4=high\n",
        "3. Number of children ever born (numerical)\n",
        "4. Wife's religion (binary) 0=Non-Islam, 1=Islam\n",
        "5. Wife's now working? (binary) 0=Yes, 1=No\n",
        "6. Husband's occupation (categorical) 1, 2, 3, 4\n",
        "7. Standard-of-living index (categorical) 1=low, 2, 3, 4=high\n",
        "8. Media exposure (binary) 0=Good, 1=Not good\n",
        "9. Contraceptive method used (class attribute) 1=No-use, 2=Long-term, 3=Short-term\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5mhAtvU4wxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[1]=df[1].astype(str)\n",
        "df[2]=df[2].astype(str)\n",
        "df[4]=df[4].astype(str)\n",
        "df[5]=df[5].astype(str)\n",
        "df[6]=df[6].astype(str)\n",
        "df[7]=df[7].astype(str)\n",
        "df[8]=df[8].astype(str)\n",
        "# df[9]=df[9].astype(str)\n",
        "\n",
        "X=df.iloc[:,:-1]\n",
        "y=df.iloc[:,-1]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozYmWD9pjfz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#label encoder to encode unseen values too\n",
        "class LabelEncoderExt(object):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
        "        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
        "        \"\"\"\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        # self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "    def fit(self, data_list):\n",
        "        \"\"\"\n",
        "        This will fit the encoder for all the unique values and introduce unknown value\n",
        "        :param data_list: A list of string\n",
        "        :return: self\n",
        "        \"\"\"\n",
        "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
        "        self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, data_list):\n",
        "        \"\"\"\n",
        "        This will transform the data_list to id list where the new values get assigned to Unknown class\n",
        "        :param data_list:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        new_data_list = list(data_list)\n",
        "        for unique_item in np.unique(data_list):\n",
        "            if unique_item not in self.label_encoder.classes_:\n",
        "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
        "\n",
        "        return self.label_encoder.transform(new_data_list)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PbWO133jfz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#encodings and split\n",
        "\n",
        "def onehot_all(X,y,ratio):\n",
        "    \n",
        "    #split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=42)\n",
        "    \n",
        "    obj_cols=X.select_dtypes('object').columns\n",
        "    enc=ce.OneHotEncoder(cols=obj_cols,handle_missing='return_nan').fit(X_train,y_train)\n",
        "    X_train=enc.transform(X_train)\n",
        "    X_test=enc.transform(X_test)\n",
        "    \n",
        "    return X_train, X_test,y_train, y_test\n",
        "\n",
        "def target_all(X,y,ratio):\n",
        "    \n",
        "    #split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=42)\n",
        "    \n",
        "#     obj_cols=X.select_dtypes('object').columns\n",
        "    enc=ce.TargetEncoder(handle_missing='return_nan').fit(X_train,y_train)\n",
        "    X_train=enc.transform(X_train)\n",
        "    X_test=enc.transform(X_test)\n",
        "    \n",
        "    return X_train,X_test,y_train, y_test\n",
        "    \n",
        "def onehot_target(X,y,ratio,thresh):\n",
        "    \n",
        "    #split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=42)\n",
        "    \n",
        "    low_card_cols,high_card_cols=[],[]\n",
        "    obj_cols=X.select_dtypes('object').columns\n",
        "    for col in obj_cols:\n",
        "        if X_train[col].nunique()<=thresh:\n",
        "            low_card_cols.append(col)\n",
        "        else:\n",
        "            high_card_cols.append(col)\n",
        "    \n",
        "    print(low_card_cols,high_card_cols)\n",
        "    \n",
        "    enc=ce.OneHotEncoder(cols=low_card_cols,handle_missing='return_nan').fit(X_train,y_train)\n",
        "    X_train=enc.transform(X_train)\n",
        "    X_test=enc.transform(X_test)\n",
        "    \n",
        "    enc=ce.TargetEncoder(cols=high_card_cols,handle_missing='return_nan').fit(X_train,y_train)\n",
        "    X_train=enc.transform(X_train)\n",
        "    X_test=enc.transform(X_test)\n",
        "    \n",
        "    return X_train,X_test,y_train, y_test\n",
        "\n",
        "def target_encode_multiclass(X,y,ratio):\n",
        "    class_names=y.unique()\n",
        "    y_classes=pd.DataFrame(columns=class_names)\n",
        "\n",
        "    for class_ in class_names:\n",
        "      y_class_=y.map(lambda x: 1 if x==class_ else 0)\n",
        "      y_classes[class_]=y_class_\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y_classes, test_size=ratio, random_state=42)\n",
        "\n",
        "    X_train_obj=X_train.select_dtypes('object')\n",
        "    X_test_obj=X_test.select_dtypes('object')\n",
        "    X_train=X_train.select_dtypes(exclude='object')\n",
        "    X_test=X_test.select_dtypes(exclude='object')\n",
        "\n",
        "    for class_ in class_names:\n",
        "      \n",
        "      enc=ce.TargetEncoder(handle_missing='return_nan').fit(X_train_obj,y_train[class_])\n",
        "      temp=enc.transform(X_train_obj)\n",
        "      temp.columns=[str(x)+'_'+str(class_) for x in temp.columns]\n",
        "      X_train=pd.concat([X_train,temp],axis=1)\n",
        "      temp=enc.transform(X_test_obj)\n",
        "      temp.columns=[str(x)+'_'+str(class_) for x in temp.columns]\n",
        "      X_test=pd.concat([X_test,temp],axis=1)\n",
        "      \n",
        "    y_train=y_train.apply(lambda row: 1 if row[1]==1 else 2 if row[2]==1 else 3 if row[3]==1 else 0, axis=1)\n",
        "    y_test=y_test.apply(lambda row: 1 if row[1]==1 else 2 if row[2]==1 else 3 if row[3]==1 else 0, axis=1)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "            \n",
        "def onehot_target_encode_multiclass(X,y,ratio,thresh):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=42)\n",
        "\n",
        "    low_card_cols,high_card_cols=[],[]\n",
        "    obj_cols=X.select_dtypes('object').columns\n",
        "    for col in obj_cols:\n",
        "        if X_train[col].nunique()<=thresh:\n",
        "            low_card_cols.append(col)\n",
        "        else:\n",
        "            high_card_cols.append(col)\n",
        "    \n",
        "    enc=ce.OneHotEncoder(cols=low_card_cols,handle_missing='return_nan').fit(X_train,y_train)\n",
        "    X_train=enc.transform(X_train)\n",
        "    X_test=enc.transform(X_test)\n",
        "\n",
        "\n",
        "    enc=ce.OneHotEncoder(handle_missing='return_nan').fit(y_train)\n",
        "    y_train_wide=enc.transform(y_train)\n",
        "    y_test_wide=enc.transform(y_test)\n",
        "\n",
        "\n",
        "    class_names=y_train_wide.columns\n",
        "    # y_classes=pd.DataFrame(columns=class_names)\n",
        "\n",
        "    # for class_ in class_names:\n",
        "    #   y_class_=y.map(lambda x: 1 if x==class_ else 0)\n",
        "    #   y_classes[class_]=y_class_\n",
        "\n",
        "    \n",
        "    X_train_obj=X_train.select_dtypes('object')\n",
        "    X_test_obj=X_test.select_dtypes('object')\n",
        "    X_train=X_train.select_dtypes(exclude='object')\n",
        "    X_test=X_test.select_dtypes(exclude='object')\n",
        "\n",
        "    for class_ in class_names:\n",
        "      \n",
        "      enc=ce.TargetEncoder(handle_missing='return_nan').fit(X_train_obj,y_train_wide[class_])\n",
        "      temp=enc.transform(X_train_obj)\n",
        "      temp.columns=[str(x)+'_'+str(class_) for x in temp.columns]\n",
        "      X_train=pd.concat([X_train,temp],axis=1)\n",
        "      temp=enc.transform(X_test_obj)\n",
        "      temp.columns=[str(x)+'_'+str(class_) for x in temp.columns]\n",
        "      X_test=pd.concat([X_test,temp],axis=1)\n",
        "      \n",
        "    # y_train=y_train.apply(lambda row: 1 if row[1]==1 else 2 if row[2]==1 else 3 if row[3]==1 else 0, axis=1)\n",
        "    # y_test=y_test.apply(lambda row: 1 if row[1]==1 else 2 if row[2]==1 else 3 if row[3]==1 else 0, axis=1)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmAQA0NNjfz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train_evaluate( X_train,X_test,y_train, y_test,cat_features=None):\n",
        "\n",
        "  # try:\n",
        "  print(\"lightgbm training with gridsearch\")\n",
        "\n",
        "  model = lgbm.LGBMClassifier(boosting_type='goss')\n",
        "  grid = GridSearchCV(estimator=model, param_grid = parameters)\n",
        "  grid.fit(X_train, y_train,verbose=0)    \n",
        "\n",
        "  model=grid.best_estimator_\n",
        "  evaluate(model,X_test,y_test)\n",
        "  # except: pass\n",
        "\n",
        "  try:\n",
        "    print(\"catboost training with gridsearch\")\n",
        "\n",
        "    model = CatBoostClassifier(\n",
        "        task_type=\"GPU\", devices='0:1'\n",
        "    )\n",
        "    grid = GridSearchCV(estimator=model, param_grid = parameters)\n",
        "    grid.fit(X_train, y_train,verbose=0)    \n",
        "\n",
        "    model=grid.best_estimator_\n",
        "    evaluate(model,X_test,y_test)\n",
        "  except:pass\n",
        "\n",
        "  try:\n",
        "    print(\"xgboost training with gridsearch\")\n",
        "\n",
        "    model = XGBClassifier(tree_method='gpu_hist', gpu_id=0)\n",
        "    grid = GridSearchCV(estimator=model, param_grid = parameters_xgb)\n",
        "    grid.fit(X_train, y_train,verbose=0)    \n",
        "\n",
        "    model=grid.best_estimator_\n",
        "    evaluate(model,X_test,y_test)\n",
        "  except:pass\n",
        "\n",
        "  try:  \n",
        "    print(\"RF training with gridsearch\")\n",
        "    \n",
        "    model=RandomForestClassifier()\n",
        "    grid = GridSearchCV(estimator=model, param_grid = parameters_RF)\n",
        "    grid.fit(X_train.fillna(value=0), y_train)    \n",
        "\n",
        "    model=grid.best_estimator_\n",
        "    evaluate(model,X_test.fillna(value=0),y_test)\n",
        "  except:pass\n",
        "    \n",
        "def train_evaluate_with_cat_feat( X_train,X_test,y_train, y_test,cat_features=None):\n",
        "  try:\n",
        "    print(\"lightgbm training with gridsearch\")\n",
        "    for col in cat_features:\n",
        "        le = LabelEncoderExt()\n",
        "        le.fit(X_train[col])\n",
        "        X_train[col]=le.transform(X_train[col])\n",
        "        X_test[col]=le.transform(X_test[col])\n",
        "\n",
        "    fit_params={'categorical_feature':cat_features}\n",
        "    model = lgbm.LGBMClassifier(boosting_type='goss')\n",
        "    grid = GridSearchCV(estimator=model, param_grid = parameters)\n",
        "    grid.fit(X_train, y_train,verbose=0,**fit_params)    \n",
        "\n",
        "    model=grid.best_estimator_\n",
        "    evaluate(model,X_test,y_test)\n",
        "  except:pass\n",
        "\n",
        "  try:\n",
        "    print(\"catboost training with gridsearch\")\n",
        "    fit_params={'cat_features':cat_features}\n",
        "    model = CatBoostClassifier(\n",
        "        task_type=\"GPU\", devices='0:1'\n",
        "    )\n",
        "    grid = GridSearchCV(estimator=model, param_grid = parameters)\n",
        "    grid.fit(X_train, y_train,verbose=0,**fit_params)    \n",
        "\n",
        "    model=grid.best_estimator_\n",
        "    evaluate(model,X_test,y_test)\n",
        "  except:pass"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8lipuKDjf0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#evaluation function\n",
        "\n",
        "def evaluate(model,X_test,y_test):\n",
        "    \n",
        "    pred=model.predict(X_test)\n",
        "    pred_proba=model.predict_proba(X_test)\n",
        "\n",
        "    print('accuracy:',accuracy_score(y_test,pred))\n",
        "    print('f1 macro:',f1_score(y_test,pred, average='macro'))\n",
        "    # print('f1_micro:',f1_score(y_test,pred, average='micro'))\n",
        "#     print(pd.Series(pred).unique())\n",
        "    print('log_loss:',log_loss(y_test,pred_proba,labels=[1,2,3]))\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDpzbqqsjf0M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f25cfb6e-a619-4463-966d-5af423cf4de7"
      },
      "source": [
        "# X=df.iloc[:,:-1]\n",
        "# y=df.iloc[:,-1:]\n",
        "# X_train,X_test,y_train, y_test=onehot_all(df.iloc[:,:-1],y,.2)\n",
        "# X_train,X_test,y_train, y_test=target_all(df.iloc[:,:-1],y,ratio=.2)\n",
        "# X_train,X_test,y_train, y_test=onehot_target(df.iloc[:,:-1],y,ratio=.2,thresh=10)\n",
        "\n",
        "\n",
        "parameters = {'depth'         : [6,8,10],\n",
        "              'learning_rate' : [.01,.05,.1,.2],\n",
        "              'iterations'    : [500,1000,2000]\n",
        "              }\n",
        "# parameters = {'depth'         : [4],\n",
        "#               'learning_rate' : [.2],\n",
        "#               'iterations'    : [50]\n",
        "#               }\n",
        "parameters_xgb = {\n",
        "'n_estimators': [500,1000,2000],\n",
        "    # 'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'max_depth' : [6,8,10],\n",
        "    'criterion' :['gini', 'entropy']\n",
        "        }\n",
        "\n",
        "# parameters_xgb = {\n",
        "# 'n_estimators': [50],\n",
        "# #     'max_features': ['auto', 'sqrt', 'log2'],\n",
        "#     'max_depth' : [4],\n",
        "# #     'criterion' :['gini', 'entropy']\n",
        "#         }\n",
        "parameters_RF={'max_depth':[6,8,10], 'n_estimators':[500,1000,2000]}\n",
        "# parameters_RF={'max_depth':[2], 'n_estimators':[10]}\n",
        "\n",
        "print(\"first with one hot for all\")\n",
        "X_train,X_test,y_train, y_test=onehot_all(X,y,.2)\n",
        "train_evaluate( X_train,X_test,y_train, y_test)\n",
        "\n",
        "print(\"now with target for all\")\n",
        "X_train,X_test,y_train, y_test=target_encode_multiclass(X,y,.2)\n",
        "train_evaluate( X_train,X_test,y_train, y_test)\n",
        "\n",
        "print(\"now with mixed for all\")\n",
        "X_train,X_test,y_train, y_test=onehot_target_encode_multiclass(X,y,.2,4)\n",
        "train_evaluate( X_train,X_test,y_train, y_test)\n",
        "\n",
        "print(\"now with native cat features support\")\n",
        "X_train,X_test,y_train, y_test=train_test_split(X, y, test_size=.2, random_state=42)\n",
        "train_evaluate_with_cat_feat(X_train,X_test,y_train, y_test,cat_features=list(X_train.select_dtypes('object').columns))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first with one hot for all\n",
            "lightgbm training with gridsearch\n",
            "accuracy: 0.5796610169491525\n",
            "f1 macro: 0.5466243668948628\n",
            "log_loss: 0.8830686769768217\n",
            "catboost training with gridsearch\n",
            "accuracy: 0.6101694915254238\n",
            "f1 macro: 0.5809340588056185\n",
            "log_loss: 0.8646339709229665\n",
            "xgboost training with gridsearch\n",
            "accuracy: 0.5423728813559322\n",
            "f1 macro: 0.5212178756951967\n",
            "log_loss: 1.1676180954529536\n",
            "RF training with gridsearch\n",
            "accuracy: 0.576271186440678\n",
            "f1 macro: 0.5349156608559477\n",
            "log_loss: 0.9132367951935777\n",
            "now with target for all\n",
            "lightgbm training with gridsearch\n",
            "accuracy: 0.5898305084745763\n",
            "f1 macro: 0.567771061965702\n",
            "log_loss: 0.8615487327171879\n",
            "catboost training with gridsearch\n",
            "accuracy: 0.6067796610169491\n",
            "f1 macro: 0.5705695346320346\n",
            "log_loss: 0.8525584085735698\n",
            "xgboost training with gridsearch\n",
            "accuracy: 0.5254237288135594\n",
            "f1 macro: 0.4990042069459362\n",
            "log_loss: 1.1751445666814724\n",
            "RF training with gridsearch\n",
            "accuracy: 0.576271186440678\n",
            "f1 macro: 0.5398320930295207\n",
            "log_loss: 0.9033826894030202\n",
            "now with mixed for all\n",
            "lightgbm training with gridsearch\n",
            "accuracy: 0.5830508474576271\n",
            "f1 macro: 0.5297687093138657\n",
            "log_loss: 0.9171520006446938\n",
            "catboost training with gridsearch\n",
            "accuracy: 0.6101694915254238\n",
            "f1 macro: 0.5809340588056185\n",
            "log_loss: 0.8646339709229665\n",
            "xgboost training with gridsearch\n",
            "accuracy: 0.5423728813559322\n",
            "f1 macro: 0.5212178756951967\n",
            "log_loss: 1.1676180954529536\n",
            "RF training with gridsearch\n",
            "accuracy: 0.576271186440678\n",
            "f1 macro: 0.5344700435094681\n",
            "log_loss: 0.9136360814418136\n",
            "now with native cat features support\n",
            "lightgbm training with gridsearch\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
            "New categorical_feature is [1, 2, 4, 5, 6, 7, 8]\n",
            "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.5796610169491525\n",
            "f1 macro: 0.5487048998499381\n",
            "log_loss: 0.8913872368199421\n",
            "catboost training with gridsearch\n",
            "accuracy: 0.5932203389830508\n",
            "f1 macro: 0.5645626946793437\n",
            "log_loss: 0.9148168200017099\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}